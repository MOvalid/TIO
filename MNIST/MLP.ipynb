{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee98f87a",
   "metadata": {},
   "source": [
    "Technniki inteligencji obliczeniowej - Multi Layer Perceptron\n",
    "\n",
    "Dane:\n",
    "\n",
    "Autorzy: Adrian Broniecki, Mateusz Gazda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e3fd54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af52189a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4df3f47a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(x_train).any())\n",
    "print(np.isnan(y_train).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5adcc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape((60000, 28 * 28)).astype('float32') / 255\n",
    "x_test = x_test.reshape((10000, 28 * 28)).astype('float32') / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0017019e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_to_categorical(y, num_classes=None):\n",
    "    \"\"\"\n",
    "    Convert class vector (integers) to one-hot encoded matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    y : array-like of shape (n_samples,)\n",
    "        Class labels as integers.\n",
    "    num_classes : int, optional\n",
    "        Total number of classes. If None, it is inferred from the data.\n",
    "    \n",
    "    Returns:\n",
    "    onehot : ndarray of shape (n_samples, num_classes)\n",
    "        One-hot encoded labels as float32.\n",
    "    \"\"\"\n",
    "    y = np.asarray(y)\n",
    "    if num_classes is None:\n",
    "        num_classes = np.max(y) + 1\n",
    "\n",
    "    onehot = np.zeros((y.shape[0], num_classes), dtype=np.float32)\n",
    "\n",
    "    onehot[np.arange(y.shape[0]), y] = 1.0\n",
    "\n",
    "    return onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33d97db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = my_to_categorical(y_train, num_classes=10)\n",
    "y_test = my_to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee17d849",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val = x_train[:48000], x_train[48000:]\n",
    "y_train, y_val = y_train[:48000], y_train[48000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumpyMLP:\n",
    "    def __init__(self, input_shape=(784,), hidden_units=[256,128], activation='relu', dropout_rate=0.0, num_classes=10, lr=0.01):\n",
    "        self.input_shape = input_shape\n",
    "        self.hidden_units = hidden_units\n",
    "        self.activation = activation\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.num_classes = num_classes\n",
    "        self.lr = lr\n",
    "        self.weights, self.biases = self._init_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bad85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def create_mlp(input_shape=(784,), \n",
    "               hidden_units=[256, 128], \n",
    "               activation='relu', \n",
    "               dropout_rate=0.3, \n",
    "               num_classes=10,\n",
    "               backend='keras'):\n",
    "    \"\"\"\n",
    "    Create a customizable MLP model with Keras or NumPy backend.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    input_shape : tuple\n",
    "        Shape of the input vector (default 784 for MNIST flattened).\n",
    "    hidden_units : list of int\n",
    "        Number of neurons in each hidden layer (default [256, 128]).\n",
    "    activation : str\n",
    "        Activation function for hidden layers (e.g., 'relu', 'tanh', 'sigmoid').\n",
    "    dropout_rate : float\n",
    "        Dropout rate applied after each hidden layer (0 = no dropout).\n",
    "    num_classes : int\n",
    "        Number of output classes (default 10 for MNIST).\n",
    "    backend : str\n",
    "        Backend to use ('keras' or 'numpy').\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    model : tf.keras.Model\n",
    "        Compiled MLP model ready for training.\n",
    "    \"\"\"\n",
    "\n",
    "    if backend == 'keras':\n",
    "        model = Sequential()\n",
    "        model.add(Dense(hidden_units[0], activation=activation, input_shape=input_shape))\n",
    "        if dropout_rate > 0:\n",
    "            model.add(Dropout(dropout_rate))\n",
    "        for units in hidden_units[1:]:\n",
    "            model.add(Dense(units, activation=activation))\n",
    "            if dropout_rate > 0:\n",
    "                model.add(Dropout(dropout_rate))\n",
    "        model.add(Dense(num_classes, activation='softmax'))\n",
    "        model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "    elif backend == 'numpy':\n",
    "        return NumpyMLP(input_shape=input_shape, hidden_units=hidden_units,\n",
    "                        activation=activation, dropout_rate=dropout_rate,\n",
    "                        num_classes=num_classes)\n",
    "    else:\n",
    "        raise ValueError(\"backend must be 'keras' or 'numpy'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b1d15e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adrian\\Desktop\\Magisterka\\SEMESTR2\\TIO\\Labolatorium\\TIO\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = create_mlp(hidden_units=[256, 128], activation='relu', dropout_rate=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4acf1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, y_train, x_val, y_val,\n",
    "                optimizer='adam', loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'], epochs=15, batch_size=128):\n",
    "    \"\"\"\n",
    "    Compile and train the MLP model.\n",
    "    Returns trained model and training history.\n",
    "    \"\"\"\n",
    "    # Select optimizer\n",
    "    if optimizer.lower() == 'adam':\n",
    "        opt = tf.keras.optimizers.Adam()\n",
    "    elif optimizer.lower() == 'sgd':\n",
    "        opt = tf.keras.optimizers.SGD()\n",
    "    else:\n",
    "        opt = tf.keras.optimizers.get(optimizer)\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=loss,\n",
    "                  metrics=metrics)\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=1)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "821dd9ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adrian\\Desktop\\Magisterka\\SEMESTR2\\TIO\\Labolatorium\\TIO\\.venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:95: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5535 - loss: 1.9180 - val_accuracy: 0.7232 - val_loss: 1.3625\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7686 - loss: 1.0515 - val_accuracy: 0.8247 - val_loss: 0.7985\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8338 - loss: 0.7016 - val_accuracy: 0.8641 - val_loss: 0.5789\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8642 - loss: 0.5477 - val_accuracy: 0.8841 - val_loss: 0.4712\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8799 - loss: 0.4665 - val_accuracy: 0.8932 - val_loss: 0.4131\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5403 - loss: 1.9382 - val_accuracy: 0.7132 - val_loss: 1.4011\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7533 - loss: 1.0872 - val_accuracy: 0.8196 - val_loss: 0.8299\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8235 - loss: 0.7339 - val_accuracy: 0.8586 - val_loss: 0.6064\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8568 - loss: 0.5753 - val_accuracy: 0.8797 - val_loss: 0.4947\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.4889 - val_accuracy: 0.8872 - val_loss: 0.4302\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.4357 - val_accuracy: 0.8958 - val_loss: 0.3905\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.4009 - val_accuracy: 0.8997 - val_loss: 0.3634\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8972 - loss: 0.3765 - val_accuracy: 0.9033 - val_loss: 0.3446\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9008 - loss: 0.3583 - val_accuracy: 0.9071 - val_loss: 0.3300\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.3441 - val_accuracy: 0.9092 - val_loss: 0.3174\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5307 - loss: 1.9215 - val_accuracy: 0.7175 - val_loss: 1.3642\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 1.0468 - val_accuracy: 0.8279 - val_loss: 0.7933\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8336 - loss: 0.6988 - val_accuracy: 0.8642 - val_loss: 0.5795\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8621 - loss: 0.5496 - val_accuracy: 0.8825 - val_loss: 0.4764\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8780 - loss: 0.4702 - val_accuracy: 0.8919 - val_loss: 0.4178\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8872 - loss: 0.4225 - val_accuracy: 0.8975 - val_loss: 0.3833\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8936 - loss: 0.3909 - val_accuracy: 0.9024 - val_loss: 0.3567\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.3678 - val_accuracy: 0.9050 - val_loss: 0.3382\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.3514 - val_accuracy: 0.9075 - val_loss: 0.3250\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.3380 - val_accuracy: 0.9105 - val_loss: 0.3133\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.3272 - val_accuracy: 0.9136 - val_loss: 0.3040\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.3184 - val_accuracy: 0.9161 - val_loss: 0.2969\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.3105 - val_accuracy: 0.9177 - val_loss: 0.2909\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.3034 - val_accuracy: 0.9197 - val_loss: 0.2851\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2972 - val_accuracy: 0.9202 - val_loss: 0.2790\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5226 - loss: 1.9756 - val_accuracy: 0.6957 - val_loss: 1.4716\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7445 - loss: 1.1441 - val_accuracy: 0.8109 - val_loss: 0.8778\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8210 - loss: 0.7674 - val_accuracy: 0.8560 - val_loss: 0.6342\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.5958 - val_accuracy: 0.8777 - val_loss: 0.5124\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8729 - loss: 0.5028 - val_accuracy: 0.8888 - val_loss: 0.4433\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.4467 - val_accuracy: 0.8940 - val_loss: 0.4010\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8903 - loss: 0.4101 - val_accuracy: 0.8991 - val_loss: 0.3717\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.3844 - val_accuracy: 0.9042 - val_loss: 0.3511\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.3662 - val_accuracy: 0.9053 - val_loss: 0.3363\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.3512 - val_accuracy: 0.9082 - val_loss: 0.3245\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3396 - val_accuracy: 0.9102 - val_loss: 0.3142\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.3297 - val_accuracy: 0.9130 - val_loss: 0.3057\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.3214 - val_accuracy: 0.9153 - val_loss: 0.2988\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.3140 - val_accuracy: 0.9164 - val_loss: 0.2932\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.3073 - val_accuracy: 0.9179 - val_loss: 0.2889\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.3016 - val_accuracy: 0.9184 - val_loss: 0.2827\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2960 - val_accuracy: 0.9197 - val_loss: 0.2789\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2913 - val_accuracy: 0.9206 - val_loss: 0.2739\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2865 - val_accuracy: 0.9225 - val_loss: 0.2694\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2819 - val_accuracy: 0.9227 - val_loss: 0.2673\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9010 - accuracy: 0.4992 - loss: 1.9323 - val_TopKCategoricalAccuracy: 0.9802 - val_accuracy: 0.7055 - val_loss: 1.3959\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9827 - accuracy: 0.7645 - loss: 1.0760 - val_TopKCategoricalAccuracy: 0.9866 - val_accuracy: 0.8179 - val_loss: 0.8171\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9880 - accuracy: 0.8313 - loss: 0.7182 - val_TopKCategoricalAccuracy: 0.9893 - val_accuracy: 0.8595 - val_loss: 0.5947\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9901 - accuracy: 0.8612 - loss: 0.5614 - val_TopKCategoricalAccuracy: 0.9917 - val_accuracy: 0.8817 - val_loss: 0.4834\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9916 - accuracy: 0.8763 - loss: 0.4772 - val_TopKCategoricalAccuracy: 0.9922 - val_accuracy: 0.8903 - val_loss: 0.4253\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.8999 - accuracy: 0.5547 - loss: 1.9274 - val_TopKCategoricalAccuracy: 0.9782 - val_accuracy: 0.7201 - val_loss: 1.3771\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9843 - accuracy: 0.7698 - loss: 1.0561 - val_TopKCategoricalAccuracy: 0.9882 - val_accuracy: 0.8317 - val_loss: 0.7984\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9891 - accuracy: 0.8342 - loss: 0.7031 - val_TopKCategoricalAccuracy: 0.9911 - val_accuracy: 0.8619 - val_loss: 0.5825\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9908 - accuracy: 0.8628 - loss: 0.5513 - val_TopKCategoricalAccuracy: 0.9922 - val_accuracy: 0.8828 - val_loss: 0.4755\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9919 - accuracy: 0.8785 - loss: 0.4699 - val_TopKCategoricalAccuracy: 0.9927 - val_accuracy: 0.8922 - val_loss: 0.4173\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9928 - accuracy: 0.8874 - loss: 0.4215 - val_TopKCategoricalAccuracy: 0.9935 - val_accuracy: 0.8979 - val_loss: 0.3788\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9936 - accuracy: 0.8936 - loss: 0.3894 - val_TopKCategoricalAccuracy: 0.9935 - val_accuracy: 0.9015 - val_loss: 0.3556\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9941 - accuracy: 0.8988 - loss: 0.3673 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.9070 - val_loss: 0.3360\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9942 - accuracy: 0.9015 - loss: 0.3504 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.9095 - val_loss: 0.3225\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9947 - accuracy: 0.9048 - loss: 0.3374 - val_TopKCategoricalAccuracy: 0.9940 - val_accuracy: 0.9126 - val_loss: 0.3120\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.8955 - accuracy: 0.5129 - loss: 1.9393 - val_TopKCategoricalAccuracy: 0.9748 - val_accuracy: 0.6930 - val_loss: 1.4115\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9823 - accuracy: 0.7585 - loss: 1.0928 - val_TopKCategoricalAccuracy: 0.9867 - val_accuracy: 0.8246 - val_loss: 0.8307\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9880 - accuracy: 0.8282 - loss: 0.7305 - val_TopKCategoricalAccuracy: 0.9906 - val_accuracy: 0.8587 - val_loss: 0.6028\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9901 - accuracy: 0.8576 - loss: 0.5704 - val_TopKCategoricalAccuracy: 0.9918 - val_accuracy: 0.8798 - val_loss: 0.4906\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9915 - accuracy: 0.8740 - loss: 0.4848 - val_TopKCategoricalAccuracy: 0.9923 - val_accuracy: 0.8903 - val_loss: 0.4280\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9924 - accuracy: 0.8844 - loss: 0.4329 - val_TopKCategoricalAccuracy: 0.9932 - val_accuracy: 0.8949 - val_loss: 0.3897\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9929 - accuracy: 0.8925 - loss: 0.3989 - val_TopKCategoricalAccuracy: 0.9934 - val_accuracy: 0.9005 - val_loss: 0.3622\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9935 - accuracy: 0.8964 - loss: 0.3752 - val_TopKCategoricalAccuracy: 0.9937 - val_accuracy: 0.9035 - val_loss: 0.3430\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9939 - accuracy: 0.9012 - loss: 0.3573 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9075 - val_loss: 0.3291\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9943 - accuracy: 0.9041 - loss: 0.3437 - val_TopKCategoricalAccuracy: 0.9937 - val_accuracy: 0.9093 - val_loss: 0.3181\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9947 - accuracy: 0.9061 - loss: 0.3327 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9122 - val_loss: 0.3101\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.9083 - loss: 0.3234 - val_TopKCategoricalAccuracy: 0.9940 - val_accuracy: 0.9136 - val_loss: 0.3016\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9099 - loss: 0.3157 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9153 - val_loss: 0.2957\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9123 - loss: 0.3091 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9172 - val_loss: 0.2901\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9143 - loss: 0.3027 - val_TopKCategoricalAccuracy: 0.9946 - val_accuracy: 0.9185 - val_loss: 0.2845\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9179 - accuracy: 0.5152 - loss: 1.9080 - val_TopKCategoricalAccuracy: 0.9772 - val_accuracy: 0.7114 - val_loss: 1.3463\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9839 - accuracy: 0.7657 - loss: 1.0358 - val_TopKCategoricalAccuracy: 0.9877 - val_accuracy: 0.8271 - val_loss: 0.7871\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9887 - accuracy: 0.8280 - loss: 0.6979 - val_TopKCategoricalAccuracy: 0.9904 - val_accuracy: 0.8590 - val_loss: 0.5813\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9906 - accuracy: 0.8587 - loss: 0.5528 - val_TopKCategoricalAccuracy: 0.9917 - val_accuracy: 0.8800 - val_loss: 0.4791\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9916 - accuracy: 0.8754 - loss: 0.4732 - val_TopKCategoricalAccuracy: 0.9923 - val_accuracy: 0.8935 - val_loss: 0.4186\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9926 - accuracy: 0.8856 - loss: 0.4239 - val_TopKCategoricalAccuracy: 0.9932 - val_accuracy: 0.8983 - val_loss: 0.3802\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9930 - accuracy: 0.8928 - loss: 0.3910 - val_TopKCategoricalAccuracy: 0.9937 - val_accuracy: 0.9032 - val_loss: 0.3563\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9939 - accuracy: 0.8983 - loss: 0.3678 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.9064 - val_loss: 0.3366\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9942 - accuracy: 0.9014 - loss: 0.3502 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9089 - val_loss: 0.3227\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9945 - accuracy: 0.9055 - loss: 0.3368 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9120 - val_loss: 0.3113\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9949 - accuracy: 0.9081 - loss: 0.3254 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9149 - val_loss: 0.3020\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9102 - loss: 0.3161 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9153 - val_loss: 0.2942\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9120 - loss: 0.3077 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9189 - val_loss: 0.2872\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9953 - accuracy: 0.9142 - loss: 0.3005 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9207 - val_loss: 0.2820\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9158 - loss: 0.2942 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9218 - val_loss: 0.2756\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9176 - loss: 0.2881 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9243 - val_loss: 0.2703\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9186 - loss: 0.2826 - val_TopKCategoricalAccuracy: 0.9945 - val_accuracy: 0.9241 - val_loss: 0.2666\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9191 - loss: 0.2773 - val_TopKCategoricalAccuracy: 0.9950 - val_accuracy: 0.9255 - val_loss: 0.2628\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9958 - accuracy: 0.9213 - loss: 0.2724 - val_TopKCategoricalAccuracy: 0.9952 - val_accuracy: 0.9254 - val_loss: 0.2591\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9960 - accuracy: 0.9221 - loss: 0.2678 - val_TopKCategoricalAccuracy: 0.9951 - val_accuracy: 0.9270 - val_loss: 0.2549\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1136 - loss: 2.3009 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1238 - loss: 2.3009 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1138 - loss: 2.3011 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1242 - loss: 2.3008 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2987 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2984 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2983 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2982 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5539 - accuracy: 0.1199 - loss: 2.3008 - val_TopKCategoricalAccuracy: 0.6622 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5422 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5943 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5699 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5557 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5732 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5408 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5561 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5145 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5447 - accuracy: 0.1253 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5170 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5192 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5129 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5293 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5187 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5199 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5129 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5280 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5195 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5372 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5605 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5301 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5131 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5362 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5173 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5507 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5196 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5674 - accuracy: 0.1142 - loss: 2.3010 - val_TopKCategoricalAccuracy: 0.5219 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5305 - accuracy: 0.1140 - loss: 2.3001 - val_TopKCategoricalAccuracy: 0.5235 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5327 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5123 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5329 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5158 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5422 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5372 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5332 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5303 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5289 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5853 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5380 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5445 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5131 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5319 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5129 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5403 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5377 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5132 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5877 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5305 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5149 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5475 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5257 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5593 - accuracy: 0.1186 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5464 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5592 - accuracy: 0.1140 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5389 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5543 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5558 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5389 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5301 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5243 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5485 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5574 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5582 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5483 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5432 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5688 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5454 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5657 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5609 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5507 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5167 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5401 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5176 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5354 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.6159 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5520 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.6258 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5527 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5691 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5542 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5798 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5671 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5814 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5584 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5875 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5620 - accuracy: 0.1140 - loss: 2.2983 - val_TopKCategoricalAccuracy: 0.5879 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5487 - accuracy: 0.1140 - loss: 2.2982 - val_TopKCategoricalAccuracy: 0.5470 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5561 - accuracy: 0.1140 - loss: 2.2981 - val_TopKCategoricalAccuracy: 0.6077 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5079 - loss: 1.9572 - val_accuracy: 0.6966 - val_loss: 1.4380\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7151 - loss: 1.1522 - val_accuracy: 0.8191 - val_loss: 0.8623\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7882 - loss: 0.8087 - val_accuracy: 0.8529 - val_loss: 0.6363\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8226 - loss: 0.6536 - val_accuracy: 0.8763 - val_loss: 0.5206\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8447 - loss: 0.5629 - val_accuracy: 0.8871 - val_loss: 0.4527\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4805 - loss: 1.9589 - val_accuracy: 0.6390 - val_loss: 1.4433\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7059 - loss: 1.1590 - val_accuracy: 0.8160 - val_loss: 0.8685\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7845 - loss: 0.8150 - val_accuracy: 0.8526 - val_loss: 0.6394\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8204 - loss: 0.6551 - val_accuracy: 0.8755 - val_loss: 0.5209\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8450 - loss: 0.5627 - val_accuracy: 0.8873 - val_loss: 0.4528\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8601 - loss: 0.5051 - val_accuracy: 0.8947 - val_loss: 0.4074\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8686 - loss: 0.4663 - val_accuracy: 0.8986 - val_loss: 0.3774\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8768 - loss: 0.4375 - val_accuracy: 0.9032 - val_loss: 0.3556\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8806 - loss: 0.4131 - val_accuracy: 0.9044 - val_loss: 0.3371\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.3972 - val_accuracy: 0.9089 - val_loss: 0.3234\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5023 - loss: 1.9596 - val_accuracy: 0.7047 - val_loss: 1.4375\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7155 - loss: 1.1500 - val_accuracy: 0.8223 - val_loss: 0.8528\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7934 - loss: 0.7959 - val_accuracy: 0.8608 - val_loss: 0.6216\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8277 - loss: 0.6386 - val_accuracy: 0.8810 - val_loss: 0.5062\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8491 - loss: 0.5469 - val_accuracy: 0.8901 - val_loss: 0.4394\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.4923 - val_accuracy: 0.8968 - val_loss: 0.3976\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8722 - loss: 0.4541 - val_accuracy: 0.9018 - val_loss: 0.3689\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8784 - loss: 0.4267 - val_accuracy: 0.9038 - val_loss: 0.3477\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.4065 - val_accuracy: 0.9069 - val_loss: 0.3315\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.3885 - val_accuracy: 0.9093 - val_loss: 0.3186\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8926 - loss: 0.3758 - val_accuracy: 0.9120 - val_loss: 0.3075\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.3627 - val_accuracy: 0.9151 - val_loss: 0.2975\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.3508 - val_accuracy: 0.9178 - val_loss: 0.2893\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.3411 - val_accuracy: 0.9193 - val_loss: 0.2815\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9038 - loss: 0.3350 - val_accuracy: 0.9208 - val_loss: 0.2755\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4868 - loss: 1.9671 - val_accuracy: 0.6964 - val_loss: 1.4558\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7144 - loss: 1.1637 - val_accuracy: 0.8192 - val_loss: 0.8689\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7859 - loss: 0.8134 - val_accuracy: 0.8545 - val_loss: 0.6392\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8226 - loss: 0.6528 - val_accuracy: 0.8736 - val_loss: 0.5219\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.5630 - val_accuracy: 0.8865 - val_loss: 0.4533\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8587 - loss: 0.5056 - val_accuracy: 0.8933 - val_loss: 0.4093\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8676 - loss: 0.4682 - val_accuracy: 0.8988 - val_loss: 0.3787\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.4371 - val_accuracy: 0.9036 - val_loss: 0.3561\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.4161 - val_accuracy: 0.9068 - val_loss: 0.3389\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8852 - loss: 0.3970 - val_accuracy: 0.9082 - val_loss: 0.3245\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.3836 - val_accuracy: 0.9119 - val_loss: 0.3121\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.3705 - val_accuracy: 0.9142 - val_loss: 0.3032\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8979 - loss: 0.3576 - val_accuracy: 0.9172 - val_loss: 0.2941\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8997 - loss: 0.3469 - val_accuracy: 0.9186 - val_loss: 0.2855\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.3381 - val_accuracy: 0.9197 - val_loss: 0.2780\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.3301 - val_accuracy: 0.9216 - val_loss: 0.2711\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.3238 - val_accuracy: 0.9229 - val_loss: 0.2660\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9084 - loss: 0.3153 - val_accuracy: 0.9253 - val_loss: 0.2594\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.3038 - val_accuracy: 0.9265 - val_loss: 0.2550\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2996 - val_accuracy: 0.9273 - val_loss: 0.2490\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.8906 - accuracy: 0.4879 - loss: 1.9935 - val_TopKCategoricalAccuracy: 0.9715 - val_accuracy: 0.7028 - val_loss: 1.4955\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9745 - accuracy: 0.6996 - loss: 1.1989 - val_TopKCategoricalAccuracy: 0.9861 - val_accuracy: 0.8078 - val_loss: 0.8977\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9836 - accuracy: 0.7772 - loss: 0.8421 - val_TopKCategoricalAccuracy: 0.9891 - val_accuracy: 0.8478 - val_loss: 0.6624\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9866 - accuracy: 0.8134 - loss: 0.6790 - val_TopKCategoricalAccuracy: 0.9912 - val_accuracy: 0.8712 - val_loss: 0.5411\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9888 - accuracy: 0.8376 - loss: 0.5871 - val_TopKCategoricalAccuracy: 0.9918 - val_accuracy: 0.8830 - val_loss: 0.4697\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.8759 - accuracy: 0.4851 - loss: 1.9835 - val_TopKCategoricalAccuracy: 0.9780 - val_accuracy: 0.6938 - val_loss: 1.4797\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9758 - accuracy: 0.7070 - loss: 1.1810 - val_TopKCategoricalAccuracy: 0.9864 - val_accuracy: 0.8190 - val_loss: 0.8752\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9836 - accuracy: 0.7859 - loss: 0.8204 - val_TopKCategoricalAccuracy: 0.9887 - val_accuracy: 0.8532 - val_loss: 0.6419\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9872 - accuracy: 0.8216 - loss: 0.6561 - val_TopKCategoricalAccuracy: 0.9907 - val_accuracy: 0.8763 - val_loss: 0.5218\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9894 - accuracy: 0.8416 - loss: 0.5682 - val_TopKCategoricalAccuracy: 0.9920 - val_accuracy: 0.8864 - val_loss: 0.4523\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9909 - accuracy: 0.8591 - loss: 0.5069 - val_TopKCategoricalAccuracy: 0.9929 - val_accuracy: 0.8933 - val_loss: 0.4082\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9912 - accuracy: 0.8679 - loss: 0.4702 - val_TopKCategoricalAccuracy: 0.9935 - val_accuracy: 0.8982 - val_loss: 0.3778\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9919 - accuracy: 0.8745 - loss: 0.4404 - val_TopKCategoricalAccuracy: 0.9940 - val_accuracy: 0.9031 - val_loss: 0.3545\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9926 - accuracy: 0.8800 - loss: 0.4184 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9055 - val_loss: 0.3365\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9929 - accuracy: 0.8848 - loss: 0.3977 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9097 - val_loss: 0.3226\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.8757 - accuracy: 0.4931 - loss: 1.9886 - val_TopKCategoricalAccuracy: 0.9779 - val_accuracy: 0.6686 - val_loss: 1.4891\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9753 - accuracy: 0.6989 - loss: 1.1976 - val_TopKCategoricalAccuracy: 0.9853 - val_accuracy: 0.8081 - val_loss: 0.9000\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9836 - accuracy: 0.7747 - loss: 0.8441 - val_TopKCategoricalAccuracy: 0.9884 - val_accuracy: 0.8490 - val_loss: 0.6636\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9860 - accuracy: 0.8148 - loss: 0.6801 - val_TopKCategoricalAccuracy: 0.9911 - val_accuracy: 0.8687 - val_loss: 0.5419\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9882 - accuracy: 0.8372 - loss: 0.5847 - val_TopKCategoricalAccuracy: 0.9916 - val_accuracy: 0.8841 - val_loss: 0.4704\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9900 - accuracy: 0.8527 - loss: 0.5269 - val_TopKCategoricalAccuracy: 0.9927 - val_accuracy: 0.8906 - val_loss: 0.4248\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9906 - accuracy: 0.8625 - loss: 0.4850 - val_TopKCategoricalAccuracy: 0.9928 - val_accuracy: 0.8957 - val_loss: 0.3906\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9920 - accuracy: 0.8704 - loss: 0.4530 - val_TopKCategoricalAccuracy: 0.9932 - val_accuracy: 0.8992 - val_loss: 0.3672\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9921 - accuracy: 0.8771 - loss: 0.4293 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9043 - val_loss: 0.3479\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9924 - accuracy: 0.8833 - loss: 0.4101 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9076 - val_loss: 0.3317\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9929 - accuracy: 0.8865 - loss: 0.3938 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9099 - val_loss: 0.3210\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9933 - accuracy: 0.8921 - loss: 0.3807 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9116 - val_loss: 0.3101\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9935 - accuracy: 0.8950 - loss: 0.3661 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9142 - val_loss: 0.3002\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9940 - accuracy: 0.8974 - loss: 0.3574 - val_TopKCategoricalAccuracy: 0.9947 - val_accuracy: 0.9179 - val_loss: 0.2927\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9941 - accuracy: 0.8993 - loss: 0.3463 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9194 - val_loss: 0.2845\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.8859 - accuracy: 0.5289 - loss: 1.9666 - val_TopKCategoricalAccuracy: 0.9812 - val_accuracy: 0.6963 - val_loss: 1.4515\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9780 - accuracy: 0.7071 - loss: 1.1665 - val_TopKCategoricalAccuracy: 0.9862 - val_accuracy: 0.8168 - val_loss: 0.8792\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9843 - accuracy: 0.7792 - loss: 0.8255 - val_TopKCategoricalAccuracy: 0.9898 - val_accuracy: 0.8506 - val_loss: 0.6498\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9875 - accuracy: 0.8157 - loss: 0.6655 - val_TopKCategoricalAccuracy: 0.9909 - val_accuracy: 0.8712 - val_loss: 0.5324\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9896 - accuracy: 0.8387 - loss: 0.5732 - val_TopKCategoricalAccuracy: 0.9919 - val_accuracy: 0.8852 - val_loss: 0.4594\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9908 - accuracy: 0.8561 - loss: 0.5122 - val_TopKCategoricalAccuracy: 0.9924 - val_accuracy: 0.8927 - val_loss: 0.4147\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9919 - accuracy: 0.8662 - loss: 0.4704 - val_TopKCategoricalAccuracy: 0.9934 - val_accuracy: 0.8996 - val_loss: 0.3810\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9926 - accuracy: 0.8748 - loss: 0.4391 - val_TopKCategoricalAccuracy: 0.9933 - val_accuracy: 0.9027 - val_loss: 0.3578\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9926 - accuracy: 0.8803 - loss: 0.4189 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9072 - val_loss: 0.3381\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9935 - accuracy: 0.8851 - loss: 0.3983 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9100 - val_loss: 0.3229\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9935 - accuracy: 0.8896 - loss: 0.3820 - val_TopKCategoricalAccuracy: 0.9946 - val_accuracy: 0.9135 - val_loss: 0.3114\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9938 - accuracy: 0.8926 - loss: 0.3690 - val_TopKCategoricalAccuracy: 0.9946 - val_accuracy: 0.9150 - val_loss: 0.2998\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9943 - accuracy: 0.8964 - loss: 0.3566 - val_TopKCategoricalAccuracy: 0.9946 - val_accuracy: 0.9181 - val_loss: 0.2910\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9946 - accuracy: 0.8991 - loss: 0.3483 - val_TopKCategoricalAccuracy: 0.9952 - val_accuracy: 0.9199 - val_loss: 0.2817\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9028 - loss: 0.3354 - val_TopKCategoricalAccuracy: 0.9949 - val_accuracy: 0.9212 - val_loss: 0.2757\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9046 - loss: 0.3258 - val_TopKCategoricalAccuracy: 0.9955 - val_accuracy: 0.9244 - val_loss: 0.2670\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9088 - loss: 0.3162 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9258 - val_loss: 0.2612\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9954 - accuracy: 0.9096 - loss: 0.3114 - val_TopKCategoricalAccuracy: 0.9956 - val_accuracy: 0.9275 - val_loss: 0.2553\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9953 - accuracy: 0.9118 - loss: 0.3040 - val_TopKCategoricalAccuracy: 0.9956 - val_accuracy: 0.9290 - val_loss: 0.2486\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9126 - loss: 0.2975 - val_TopKCategoricalAccuracy: 0.9956 - val_accuracy: 0.9308 - val_loss: 0.2439\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1175 - loss: 2.3007 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1190 - loss: 2.3009 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1219 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3004 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1215 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3004 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5740 - accuracy: 0.1193 - loss: 2.3010 - val_TopKCategoricalAccuracy: 0.6602 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5550 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.6219 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5528 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5860 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5515 - accuracy: 0.1140 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5663 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5493 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5645 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5714 - accuracy: 0.1200 - loss: 2.3008 - val_TopKCategoricalAccuracy: 0.5148 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5381 - accuracy: 0.1140 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5148 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5344 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5444 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5400 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5130 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5461 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5129 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5462 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5132 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5428 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5539 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5528 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5736 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5582 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5202 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5490 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5783 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5765 - accuracy: 0.1251 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.5658 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5378 - accuracy: 0.1140 - loss: 2.3001 - val_TopKCategoricalAccuracy: 0.5867 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5446 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5215 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5415 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5142 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5421 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5317 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5384 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5127 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5392 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5122 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5397 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5154 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5451 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5213 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5578 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5214 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5480 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5400 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5460 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5608 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5516 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5129 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5496 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5438 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5296 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Testing: hidden_units=[128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5667 - accuracy: 0.1231 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.5803 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5559 - accuracy: 0.1140 - loss: 2.3001 - val_TopKCategoricalAccuracy: 0.5774 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5434 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5586 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5456 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5677 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5423 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5684 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5443 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5814 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5402 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5412 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5142 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5424 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5287 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5446 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5784 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5425 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.6117 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5487 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5130 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5469 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5894 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5512 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5809 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5485 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5844 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5524 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5530 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5500 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.5677 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5692 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5617 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5510 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5720 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5590 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5340 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5908 - loss: 1.7851 - val_accuracy: 0.7899 - val_loss: 1.1171\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8185 - loss: 0.8351 - val_accuracy: 0.8618 - val_loss: 0.6105\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8643 - loss: 0.5492 - val_accuracy: 0.8863 - val_loss: 0.4533\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8837 - loss: 0.4430 - val_accuracy: 0.8969 - val_loss: 0.3870\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.3912 - val_accuracy: 0.9018 - val_loss: 0.3505\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5761 - loss: 1.7953 - val_accuracy: 0.7812 - val_loss: 1.1266\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8141 - loss: 0.8433 - val_accuracy: 0.8618 - val_loss: 0.6162\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.5537 - val_accuracy: 0.8847 - val_loss: 0.4564\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.4450 - val_accuracy: 0.8964 - val_loss: 0.3884\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8937 - loss: 0.3926 - val_accuracy: 0.9031 - val_loss: 0.3523\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8989 - loss: 0.3622 - val_accuracy: 0.9072 - val_loss: 0.3303\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9038 - loss: 0.3424 - val_accuracy: 0.9093 - val_loss: 0.3147\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9070 - loss: 0.3288 - val_accuracy: 0.9121 - val_loss: 0.3048\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9095 - loss: 0.3185 - val_accuracy: 0.9145 - val_loss: 0.2971\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.3105 - val_accuracy: 0.9156 - val_loss: 0.2924\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5632 - loss: 1.7914 - val_accuracy: 0.7837 - val_loss: 1.1347\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.8523 - val_accuracy: 0.8566 - val_loss: 0.6271\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8617 - loss: 0.5601 - val_accuracy: 0.8848 - val_loss: 0.4606\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8829 - loss: 0.4480 - val_accuracy: 0.8943 - val_loss: 0.3907\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8924 - loss: 0.3940 - val_accuracy: 0.9009 - val_loss: 0.3528\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8979 - loss: 0.3628 - val_accuracy: 0.9068 - val_loss: 0.3295\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9032 - loss: 0.3427 - val_accuracy: 0.9083 - val_loss: 0.3158\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9064 - loss: 0.3289 - val_accuracy: 0.9123 - val_loss: 0.3042\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.3185 - val_accuracy: 0.9159 - val_loss: 0.2982\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.3109 - val_accuracy: 0.9179 - val_loss: 0.2900\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9129 - loss: 0.3042 - val_accuracy: 0.9174 - val_loss: 0.2864\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2994 - val_accuracy: 0.9193 - val_loss: 0.2850\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9156 - loss: 0.2949 - val_accuracy: 0.9202 - val_loss: 0.2803\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2911 - val_accuracy: 0.9194 - val_loss: 0.2771\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2882 - val_accuracy: 0.9217 - val_loss: 0.2763\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5729 - loss: 1.7807 - val_accuracy: 0.7876 - val_loss: 1.1142\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8174 - loss: 0.8336 - val_accuracy: 0.8628 - val_loss: 0.6108\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8648 - loss: 0.5510 - val_accuracy: 0.8835 - val_loss: 0.4575\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.4455 - val_accuracy: 0.8964 - val_loss: 0.3902\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.3936 - val_accuracy: 0.9025 - val_loss: 0.3550\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8991 - loss: 0.3636 - val_accuracy: 0.9065 - val_loss: 0.3304\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9027 - loss: 0.3439 - val_accuracy: 0.9093 - val_loss: 0.3158\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9060 - loss: 0.3300 - val_accuracy: 0.9118 - val_loss: 0.3051\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9093 - loss: 0.3192 - val_accuracy: 0.9134 - val_loss: 0.2984\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.3113 - val_accuracy: 0.9169 - val_loss: 0.2904\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.3049 - val_accuracy: 0.9184 - val_loss: 0.2867\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9141 - loss: 0.2995 - val_accuracy: 0.9196 - val_loss: 0.2840\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2953 - val_accuracy: 0.9217 - val_loss: 0.2797\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2916 - val_accuracy: 0.9209 - val_loss: 0.2760\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9180 - loss: 0.2887 - val_accuracy: 0.9212 - val_loss: 0.2751\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.2859 - val_accuracy: 0.9218 - val_loss: 0.2732\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.2834 - val_accuracy: 0.9223 - val_loss: 0.2723\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9197 - loss: 0.2813 - val_accuracy: 0.9230 - val_loss: 0.2713\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9207 - loss: 0.2793 - val_accuracy: 0.9233 - val_loss: 0.2699\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.2776 - val_accuracy: 0.9232 - val_loss: 0.2678\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9168 - accuracy: 0.5912 - loss: 1.7869 - val_TopKCategoricalAccuracy: 0.9822 - val_accuracy: 0.7770 - val_loss: 1.1273\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9855 - accuracy: 0.8121 - loss: 0.8428 - val_TopKCategoricalAccuracy: 0.9895 - val_accuracy: 0.8571 - val_loss: 0.6151\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9901 - accuracy: 0.8617 - loss: 0.5536 - val_TopKCategoricalAccuracy: 0.9920 - val_accuracy: 0.8857 - val_loss: 0.4561\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9918 - accuracy: 0.8829 - loss: 0.4448 - val_TopKCategoricalAccuracy: 0.9929 - val_accuracy: 0.8960 - val_loss: 0.3870\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9931 - accuracy: 0.8931 - loss: 0.3914 - val_TopKCategoricalAccuracy: 0.9935 - val_accuracy: 0.9009 - val_loss: 0.3499\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9101 - accuracy: 0.5543 - loss: 1.7874 - val_TopKCategoricalAccuracy: 0.9822 - val_accuracy: 0.7882 - val_loss: 1.1135\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9864 - accuracy: 0.8159 - loss: 0.8327 - val_TopKCategoricalAccuracy: 0.9895 - val_accuracy: 0.8608 - val_loss: 0.6079\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9906 - accuracy: 0.8634 - loss: 0.5487 - val_TopKCategoricalAccuracy: 0.9918 - val_accuracy: 0.8848 - val_loss: 0.4537\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9920 - accuracy: 0.8826 - loss: 0.4436 - val_TopKCategoricalAccuracy: 0.9926 - val_accuracy: 0.8947 - val_loss: 0.3872\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9931 - accuracy: 0.8922 - loss: 0.3924 - val_TopKCategoricalAccuracy: 0.9933 - val_accuracy: 0.9011 - val_loss: 0.3519\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9935 - accuracy: 0.8994 - loss: 0.3623 - val_TopKCategoricalAccuracy: 0.9936 - val_accuracy: 0.9064 - val_loss: 0.3305\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9944 - accuracy: 0.9037 - loss: 0.3424 - val_TopKCategoricalAccuracy: 0.9940 - val_accuracy: 0.9101 - val_loss: 0.3148\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9946 - accuracy: 0.9073 - loss: 0.3289 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.9126 - val_loss: 0.3044\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9947 - accuracy: 0.9098 - loss: 0.3187 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9138 - val_loss: 0.2972\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9114 - loss: 0.3107 - val_TopKCategoricalAccuracy: 0.9940 - val_accuracy: 0.9171 - val_loss: 0.2908\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9035 - accuracy: 0.5770 - loss: 1.7847 - val_TopKCategoricalAccuracy: 0.9842 - val_accuracy: 0.7787 - val_loss: 1.1179\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9866 - accuracy: 0.8156 - loss: 0.8368 - val_TopKCategoricalAccuracy: 0.9897 - val_accuracy: 0.8608 - val_loss: 0.6105\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9906 - accuracy: 0.8656 - loss: 0.5487 - val_TopKCategoricalAccuracy: 0.9913 - val_accuracy: 0.8884 - val_loss: 0.4515\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9921 - accuracy: 0.8841 - loss: 0.4415 - val_TopKCategoricalAccuracy: 0.9927 - val_accuracy: 0.8964 - val_loss: 0.3845\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9933 - accuracy: 0.8931 - loss: 0.3894 - val_TopKCategoricalAccuracy: 0.9933 - val_accuracy: 0.9032 - val_loss: 0.3495\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9940 - accuracy: 0.8992 - loss: 0.3598 - val_TopKCategoricalAccuracy: 0.9937 - val_accuracy: 0.9071 - val_loss: 0.3311\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9942 - accuracy: 0.9035 - loss: 0.3410 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9087 - val_loss: 0.3151\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9946 - accuracy: 0.9069 - loss: 0.3274 - val_TopKCategoricalAccuracy: 0.9939 - val_accuracy: 0.9133 - val_loss: 0.3033\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9947 - accuracy: 0.9094 - loss: 0.3173 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9148 - val_loss: 0.2966\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.9120 - loss: 0.3100 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9151 - val_loss: 0.2906\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9949 - accuracy: 0.9134 - loss: 0.3038 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9179 - val_loss: 0.2872\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9143 - loss: 0.2989 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9190 - val_loss: 0.2834\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9156 - loss: 0.2947 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9204 - val_loss: 0.2796\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9176 - loss: 0.2910 - val_TopKCategoricalAccuracy: 0.9945 - val_accuracy: 0.9213 - val_loss: 0.2769\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9179 - loss: 0.2879 - val_TopKCategoricalAccuracy: 0.9946 - val_accuracy: 0.9215 - val_loss: 0.2739\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9186 - accuracy: 0.5966 - loss: 1.7786 - val_TopKCategoricalAccuracy: 0.9833 - val_accuracy: 0.7857 - val_loss: 1.1125\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9862 - accuracy: 0.8163 - loss: 0.8346 - val_TopKCategoricalAccuracy: 0.9899 - val_accuracy: 0.8543 - val_loss: 0.6144\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9901 - accuracy: 0.8626 - loss: 0.5526 - val_TopKCategoricalAccuracy: 0.9923 - val_accuracy: 0.8862 - val_loss: 0.4569\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9919 - accuracy: 0.8834 - loss: 0.4460 - val_TopKCategoricalAccuracy: 0.9927 - val_accuracy: 0.8953 - val_loss: 0.3897\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9933 - accuracy: 0.8929 - loss: 0.3935 - val_TopKCategoricalAccuracy: 0.9936 - val_accuracy: 0.9032 - val_loss: 0.3525\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9939 - accuracy: 0.8987 - loss: 0.3632 - val_TopKCategoricalAccuracy: 0.9934 - val_accuracy: 0.9077 - val_loss: 0.3314\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9944 - accuracy: 0.9041 - loss: 0.3431 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9095 - val_loss: 0.3165\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.9062 - loss: 0.3292 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.9126 - val_loss: 0.3053\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.9094 - loss: 0.3186 - val_TopKCategoricalAccuracy: 0.9939 - val_accuracy: 0.9149 - val_loss: 0.2983\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.9119 - loss: 0.3110 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9169 - val_loss: 0.2915\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9125 - loss: 0.3047 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9193 - val_loss: 0.2875\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9147 - loss: 0.2998 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9197 - val_loss: 0.2825\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9162 - loss: 0.2953 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9189 - val_loss: 0.2801\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9173 - loss: 0.2917 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9201 - val_loss: 0.2782\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9179 - loss: 0.2883 - val_TopKCategoricalAccuracy: 0.9947 - val_accuracy: 0.9202 - val_loss: 0.2770\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9954 - accuracy: 0.9188 - loss: 0.2857 - val_TopKCategoricalAccuracy: 0.9947 - val_accuracy: 0.9222 - val_loss: 0.2724\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9953 - accuracy: 0.9194 - loss: 0.2837 - val_TopKCategoricalAccuracy: 0.9946 - val_accuracy: 0.9228 - val_loss: 0.2715\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9197 - loss: 0.2813 - val_TopKCategoricalAccuracy: 0.9949 - val_accuracy: 0.9229 - val_loss: 0.2719\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9208 - loss: 0.2796 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9228 - val_loss: 0.2695\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9954 - accuracy: 0.9212 - loss: 0.2781 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9240 - val_loss: 0.2671\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1142 - loss: 2.3015 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3007 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3004 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3002 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1142 - loss: 2.3016 - val_accuracy: 0.1060 - val_loss: 2.3019\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3009 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3007 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3006 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3002 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1144 - loss: 2.3016 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3009 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3007 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3002 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1168 - loss: 2.3010 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2987 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2984 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2982 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2981 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2979 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2978 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2976 - val_accuracy: 0.1060 - val_loss: 2.2986\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5327 - accuracy: 0.1134 - loss: 2.3018 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3020\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5272 - accuracy: 0.1140 - loss: 2.3010 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5289 - accuracy: 0.1140 - loss: 2.3008 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5241 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5861 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5450 - accuracy: 0.1140 - loss: 2.3005 - val_TopKCategoricalAccuracy: 0.6153 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5161 - accuracy: 0.1153 - loss: 2.3016 - val_TopKCategoricalAccuracy: 0.4997 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5220 - accuracy: 0.1140 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.5284 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5389 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5210 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5232 - accuracy: 0.1140 - loss: 2.3006 - val_TopKCategoricalAccuracy: 0.5773 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5440 - accuracy: 0.1140 - loss: 2.3004 - val_TopKCategoricalAccuracy: 0.5373 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5276 - accuracy: 0.1140 - loss: 2.3003 - val_TopKCategoricalAccuracy: 0.5525 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5533 - accuracy: 0.1140 - loss: 2.3001 - val_TopKCategoricalAccuracy: 0.5138 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5370 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5308 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5390 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5320 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5529 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5114 - accuracy: 0.1182 - loss: 2.3016 - val_TopKCategoricalAccuracy: 0.5057 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5170 - accuracy: 0.1140 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.5107 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5127 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5150 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5198 - accuracy: 0.1140 - loss: 2.3006 - val_TopKCategoricalAccuracy: 0.5130 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5195 - accuracy: 0.1140 - loss: 2.3004 - val_TopKCategoricalAccuracy: 0.5271 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5335 - accuracy: 0.1140 - loss: 2.3003 - val_TopKCategoricalAccuracy: 0.5228 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5326 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5259 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5549 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5121 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5377 - accuracy: 0.1140 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5211 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5313 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5274 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5373 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5295 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5365 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5293 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5412 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5393 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5504 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5449 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5525 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5474 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5076 - accuracy: 0.1131 - loss: 2.3017 - val_TopKCategoricalAccuracy: 0.5247 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5010 - accuracy: 0.1140 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.4731 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5144 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5109 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5125 - accuracy: 0.1140 - loss: 2.3006 - val_TopKCategoricalAccuracy: 0.5174 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5182 - accuracy: 0.1140 - loss: 2.3004 - val_TopKCategoricalAccuracy: 0.5116 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5257 - accuracy: 0.1140 - loss: 2.3003 - val_TopKCategoricalAccuracy: 0.5183 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5246 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5125 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5233 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5337 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5252 - accuracy: 0.1140 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5268 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5349 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5459 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5356 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5398 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5418 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5139 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5385 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5406 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5334 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5135 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5365 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5817 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5556 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5437 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5531 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5178 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5553 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5534 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5391 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5886 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5521 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.6076 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5536 - loss: 1.8218 - val_accuracy: 0.7681 - val_loss: 1.1771\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7993 - loss: 0.8982 - val_accuracy: 0.8480 - val_loss: 0.6580\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8496 - loss: 0.6028 - val_accuracy: 0.8799 - val_loss: 0.4891\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8719 - loss: 0.4879 - val_accuracy: 0.8925 - val_loss: 0.4117\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8830 - loss: 0.4283 - val_accuracy: 0.8981 - val_loss: 0.3709\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5406 - loss: 1.8407 - val_accuracy: 0.7688 - val_loss: 1.2031\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7989 - loss: 0.9084 - val_accuracy: 0.8550 - val_loss: 0.6581\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8527 - loss: 0.6001 - val_accuracy: 0.8841 - val_loss: 0.4822\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.4822 - val_accuracy: 0.8936 - val_loss: 0.4064\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.4253 - val_accuracy: 0.8980 - val_loss: 0.3664\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8907 - loss: 0.3928 - val_accuracy: 0.9034 - val_loss: 0.3442\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.3710 - val_accuracy: 0.9059 - val_loss: 0.3269\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8991 - loss: 0.3569 - val_accuracy: 0.9079 - val_loss: 0.3154\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9007 - loss: 0.3452 - val_accuracy: 0.9110 - val_loss: 0.3070\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9029 - loss: 0.3377 - val_accuracy: 0.9142 - val_loss: 0.3000\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5590 - loss: 1.8284 - val_accuracy: 0.7504 - val_loss: 1.1897\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7929 - loss: 0.9061 - val_accuracy: 0.8537 - val_loss: 0.6591\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8506 - loss: 0.6032 - val_accuracy: 0.8820 - val_loss: 0.4853\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8730 - loss: 0.4846 - val_accuracy: 0.8905 - val_loss: 0.4089\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8841 - loss: 0.4267 - val_accuracy: 0.8991 - val_loss: 0.3685\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8908 - loss: 0.3937 - val_accuracy: 0.9030 - val_loss: 0.3435\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.3717 - val_accuracy: 0.9069 - val_loss: 0.3266\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8986 - loss: 0.3571 - val_accuracy: 0.9097 - val_loss: 0.3142\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9002 - loss: 0.3455 - val_accuracy: 0.9126 - val_loss: 0.3066\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9041 - loss: 0.3368 - val_accuracy: 0.9144 - val_loss: 0.2993\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.3284 - val_accuracy: 0.9151 - val_loss: 0.2943\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.3237 - val_accuracy: 0.9166 - val_loss: 0.2910\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.3185 - val_accuracy: 0.9164 - val_loss: 0.2888\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.3152 - val_accuracy: 0.9185 - val_loss: 0.2847\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9114 - loss: 0.3111 - val_accuracy: 0.9190 - val_loss: 0.2831\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.5842 - loss: 1.8260 - val_accuracy: 0.7779 - val_loss: 1.1750\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8002 - loss: 0.8926 - val_accuracy: 0.8521 - val_loss: 0.6488\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8514 - loss: 0.5956 - val_accuracy: 0.8817 - val_loss: 0.4802\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.4806 - val_accuracy: 0.8923 - val_loss: 0.4083\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8842 - loss: 0.4252 - val_accuracy: 0.8988 - val_loss: 0.3679\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.3926 - val_accuracy: 0.9038 - val_loss: 0.3436\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8953 - loss: 0.3699 - val_accuracy: 0.9064 - val_loss: 0.3276\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8983 - loss: 0.3562 - val_accuracy: 0.9095 - val_loss: 0.3162\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9011 - loss: 0.3462 - val_accuracy: 0.9122 - val_loss: 0.3072\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9022 - loss: 0.3367 - val_accuracy: 0.9137 - val_loss: 0.3007\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9051 - loss: 0.3294 - val_accuracy: 0.9171 - val_loss: 0.2946\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.3247 - val_accuracy: 0.9172 - val_loss: 0.2908\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.3201 - val_accuracy: 0.9171 - val_loss: 0.2871\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.3148 - val_accuracy: 0.9189 - val_loss: 0.2855\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.3114 - val_accuracy: 0.9197 - val_loss: 0.2825\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.3075 - val_accuracy: 0.9208 - val_loss: 0.2796\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.3056 - val_accuracy: 0.9218 - val_loss: 0.2767\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.3037 - val_accuracy: 0.9212 - val_loss: 0.2759\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.3003 - val_accuracy: 0.9210 - val_loss: 0.2745\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.3001 - val_accuracy: 0.9227 - val_loss: 0.2735\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9017 - accuracy: 0.5557 - loss: 1.8264 - val_TopKCategoricalAccuracy: 0.9823 - val_accuracy: 0.7703 - val_loss: 1.1870\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9851 - accuracy: 0.7986 - loss: 0.9029 - val_TopKCategoricalAccuracy: 0.9890 - val_accuracy: 0.8477 - val_loss: 0.6615\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9895 - accuracy: 0.8479 - loss: 0.6044 - val_TopKCategoricalAccuracy: 0.9913 - val_accuracy: 0.8773 - val_loss: 0.4898\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9911 - accuracy: 0.8712 - loss: 0.4885 - val_TopKCategoricalAccuracy: 0.9927 - val_accuracy: 0.8928 - val_loss: 0.4134\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9922 - accuracy: 0.8824 - loss: 0.4306 - val_TopKCategoricalAccuracy: 0.9931 - val_accuracy: 0.8980 - val_loss: 0.3705\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9084 - accuracy: 0.5459 - loss: 1.8273 - val_TopKCategoricalAccuracy: 0.9799 - val_accuracy: 0.7564 - val_loss: 1.1927\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9847 - accuracy: 0.7944 - loss: 0.9063 - val_TopKCategoricalAccuracy: 0.9886 - val_accuracy: 0.8512 - val_loss: 0.6592\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9895 - accuracy: 0.8492 - loss: 0.6027 - val_TopKCategoricalAccuracy: 0.9915 - val_accuracy: 0.8797 - val_loss: 0.4883\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9906 - accuracy: 0.8705 - loss: 0.4888 - val_TopKCategoricalAccuracy: 0.9925 - val_accuracy: 0.8923 - val_loss: 0.4106\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9919 - accuracy: 0.8821 - loss: 0.4296 - val_TopKCategoricalAccuracy: 0.9927 - val_accuracy: 0.8973 - val_loss: 0.3708\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9930 - accuracy: 0.8895 - loss: 0.3951 - val_TopKCategoricalAccuracy: 0.9933 - val_accuracy: 0.9028 - val_loss: 0.3452\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9931 - accuracy: 0.8946 - loss: 0.3736 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9057 - val_loss: 0.3285\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9939 - accuracy: 0.8989 - loss: 0.3567 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.9109 - val_loss: 0.3192\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9941 - accuracy: 0.9014 - loss: 0.3457 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9110 - val_loss: 0.3071\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9945 - accuracy: 0.9044 - loss: 0.3367 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.9124 - val_loss: 0.3027\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9115 - accuracy: 0.5512 - loss: 1.8238 - val_TopKCategoricalAccuracy: 0.9826 - val_accuracy: 0.7748 - val_loss: 1.1888\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9853 - accuracy: 0.7992 - loss: 0.9061 - val_TopKCategoricalAccuracy: 0.9887 - val_accuracy: 0.8528 - val_loss: 0.6590\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9899 - accuracy: 0.8516 - loss: 0.6018 - val_TopKCategoricalAccuracy: 0.9915 - val_accuracy: 0.8804 - val_loss: 0.4849\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9910 - accuracy: 0.8724 - loss: 0.4847 - val_TopKCategoricalAccuracy: 0.9925 - val_accuracy: 0.8923 - val_loss: 0.4082\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9924 - accuracy: 0.8827 - loss: 0.4272 - val_TopKCategoricalAccuracy: 0.9930 - val_accuracy: 0.8983 - val_loss: 0.3692\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9926 - accuracy: 0.8899 - loss: 0.3945 - val_TopKCategoricalAccuracy: 0.9931 - val_accuracy: 0.9042 - val_loss: 0.3445\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9932 - accuracy: 0.8938 - loss: 0.3724 - val_TopKCategoricalAccuracy: 0.9937 - val_accuracy: 0.9075 - val_loss: 0.3287\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9938 - accuracy: 0.8979 - loss: 0.3563 - val_TopKCategoricalAccuracy: 0.9939 - val_accuracy: 0.9105 - val_loss: 0.3157\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9940 - accuracy: 0.9021 - loss: 0.3460 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9112 - val_loss: 0.3093\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9944 - accuracy: 0.9045 - loss: 0.3370 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9143 - val_loss: 0.3004\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9942 - accuracy: 0.9057 - loss: 0.3311 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9172 - val_loss: 0.2953\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9947 - accuracy: 0.9065 - loss: 0.3245 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9175 - val_loss: 0.2904\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9946 - accuracy: 0.9085 - loss: 0.3202 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9177 - val_loss: 0.2885\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9946 - accuracy: 0.9097 - loss: 0.3144 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9178 - val_loss: 0.2849\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9945 - accuracy: 0.9101 - loss: 0.3132 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9208 - val_loss: 0.2816\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9009 - accuracy: 0.5824 - loss: 1.8228 - val_TopKCategoricalAccuracy: 0.9802 - val_accuracy: 0.7698 - val_loss: 1.1780\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9834 - accuracy: 0.7984 - loss: 0.9003 - val_TopKCategoricalAccuracy: 0.9881 - val_accuracy: 0.8526 - val_loss: 0.6589\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9889 - accuracy: 0.8511 - loss: 0.6024 - val_TopKCategoricalAccuracy: 0.9909 - val_accuracy: 0.8824 - val_loss: 0.4866\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9908 - accuracy: 0.8723 - loss: 0.4848 - val_TopKCategoricalAccuracy: 0.9925 - val_accuracy: 0.8938 - val_loss: 0.4096\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9925 - accuracy: 0.8836 - loss: 0.4265 - val_TopKCategoricalAccuracy: 0.9928 - val_accuracy: 0.8983 - val_loss: 0.3695\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9925 - accuracy: 0.8910 - loss: 0.3923 - val_TopKCategoricalAccuracy: 0.9933 - val_accuracy: 0.9029 - val_loss: 0.3439\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9934 - accuracy: 0.8947 - loss: 0.3727 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.9061 - val_loss: 0.3271\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9934 - accuracy: 0.8991 - loss: 0.3570 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9097 - val_loss: 0.3161\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9937 - accuracy: 0.9009 - loss: 0.3451 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9115 - val_loss: 0.3074\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9943 - accuracy: 0.9036 - loss: 0.3376 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9134 - val_loss: 0.3007\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9943 - accuracy: 0.9070 - loss: 0.3280 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9147 - val_loss: 0.2947\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9945 - accuracy: 0.9071 - loss: 0.3234 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9164 - val_loss: 0.2900\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9946 - accuracy: 0.9091 - loss: 0.3182 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9180 - val_loss: 0.2872\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.9101 - loss: 0.3131 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9198 - val_loss: 0.2832\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9947 - accuracy: 0.9100 - loss: 0.3130 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9193 - val_loss: 0.2817\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.9947 - accuracy: 0.9123 - loss: 0.3072 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9210 - val_loss: 0.2788\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9128 - loss: 0.3056 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9222 - val_loss: 0.2770\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9133 - loss: 0.3033 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9221 - val_loss: 0.2747\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.9134 - loss: 0.3011 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9229 - val_loss: 0.2732\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9954 - accuracy: 0.9144 - loss: 0.2980 - val_TopKCategoricalAccuracy: 0.9949 - val_accuracy: 0.9229 - val_loss: 0.2733\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1149 - loss: 2.3013 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3006 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3002 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1172 - loss: 2.3006 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1167 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1134 - loss: 2.3017 - val_accuracy: 0.1060 - val_loss: 2.3019\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3011 - val_accuracy: 0.1060 - val_loss: 2.3019\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3010 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3007 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3006 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3004 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3002 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5343 - accuracy: 0.1127 - loss: 2.3015 - val_TopKCategoricalAccuracy: 0.5593 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5277 - accuracy: 0.1140 - loss: 2.3008 - val_TopKCategoricalAccuracy: 0.5214 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5281 - accuracy: 0.1140 - loss: 2.3006 - val_TopKCategoricalAccuracy: 0.5097 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5249 - accuracy: 0.1140 - loss: 2.3005 - val_TopKCategoricalAccuracy: 0.5343 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5301 - accuracy: 0.1140 - loss: 2.3004 - val_TopKCategoricalAccuracy: 0.5157 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.4993 - accuracy: 0.1110 - loss: 2.3020 - val_TopKCategoricalAccuracy: 0.5107 - val_accuracy: 0.1060 - val_loss: 2.3020\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5120 - accuracy: 0.1140 - loss: 2.3012 - val_TopKCategoricalAccuracy: 0.5107 - val_accuracy: 0.1060 - val_loss: 2.3019\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5134 - accuracy: 0.1140 - loss: 2.3010 - val_TopKCategoricalAccuracy: 0.5105 - val_accuracy: 0.1060 - val_loss: 2.3019\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5159 - accuracy: 0.1140 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.4984 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5138 - accuracy: 0.1140 - loss: 2.3008 - val_TopKCategoricalAccuracy: 0.4940 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5188 - accuracy: 0.1140 - loss: 2.3006 - val_TopKCategoricalAccuracy: 0.5458 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5230 - accuracy: 0.1140 - loss: 2.3005 - val_TopKCategoricalAccuracy: 0.5133 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5271 - accuracy: 0.1140 - loss: 2.3003 - val_TopKCategoricalAccuracy: 0.5125 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5253 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5082 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5242 - accuracy: 0.1140 - loss: 2.3001 - val_TopKCategoricalAccuracy: 0.5428 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5448 - accuracy: 0.1142 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.5491 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5345 - accuracy: 0.1140 - loss: 2.3003 - val_TopKCategoricalAccuracy: 0.5183 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5336 - accuracy: 0.1140 - loss: 2.3001 - val_TopKCategoricalAccuracy: 0.5305 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5395 - accuracy: 0.1140 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5203 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5413 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5494 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5380 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5484 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5396 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5717 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5489 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5709 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5469 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5719 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5470 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5257 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5482 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5957 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5572 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5772 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5592 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.6296 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5614 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5868 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5618 - accuracy: 0.1140 - loss: 2.2983 - val_TopKCategoricalAccuracy: 0.5580 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Testing: hidden_units=[128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5044 - accuracy: 0.1157 - loss: 2.3016 - val_TopKCategoricalAccuracy: 0.5181 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5189 - accuracy: 0.1140 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.5163 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5198 - accuracy: 0.1140 - loss: 2.3006 - val_TopKCategoricalAccuracy: 0.5293 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5229 - accuracy: 0.1140 - loss: 2.3005 - val_TopKCategoricalAccuracy: 0.5098 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5231 - accuracy: 0.1140 - loss: 2.3004 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5242 - accuracy: 0.1140 - loss: 2.3003 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5268 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5129 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5259 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5132 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5274 - accuracy: 0.1140 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5424 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5332 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5687 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5346 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5107 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5322 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5135 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5467 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5378 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5349 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5584 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5410 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5127 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5401 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5456 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5155 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5564 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5228 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5471 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5309 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5457 - accuracy: 0.1140 - loss: 2.2983 - val_TopKCategoricalAccuracy: 0.6323 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6692 - loss: 1.1873 - val_accuracy: 0.8468 - val_loss: 0.5411\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8668 - loss: 0.4629 - val_accuracy: 0.8942 - val_loss: 0.3752\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8924 - loss: 0.3718 - val_accuracy: 0.9038 - val_loss: 0.3334\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9026 - loss: 0.3360 - val_accuracy: 0.9123 - val_loss: 0.3025\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.3110 - val_accuracy: 0.9177 - val_loss: 0.2807\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6552 - loss: 1.1991 - val_accuracy: 0.8478 - val_loss: 0.5605\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8641 - loss: 0.4731 - val_accuracy: 0.8908 - val_loss: 0.3762\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8928 - loss: 0.3732 - val_accuracy: 0.9039 - val_loss: 0.3308\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.3383 - val_accuracy: 0.9112 - val_loss: 0.3060\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.3131 - val_accuracy: 0.9168 - val_loss: 0.2871\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.2902 - val_accuracy: 0.9220 - val_loss: 0.2624\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.2715 - val_accuracy: 0.9243 - val_loss: 0.2554\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9265 - loss: 0.2525 - val_accuracy: 0.9315 - val_loss: 0.2350\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9309 - loss: 0.2362 - val_accuracy: 0.9370 - val_loss: 0.2255\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9355 - loss: 0.2198 - val_accuracy: 0.9406 - val_loss: 0.2070\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6482 - loss: 1.1713 - val_accuracy: 0.8413 - val_loss: 0.5581\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8586 - loss: 0.4826 - val_accuracy: 0.8875 - val_loss: 0.3966\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8867 - loss: 0.3895 - val_accuracy: 0.9011 - val_loss: 0.3391\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9006 - loss: 0.3468 - val_accuracy: 0.9105 - val_loss: 0.3092\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9078 - loss: 0.3181 - val_accuracy: 0.9175 - val_loss: 0.2899\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9154 - loss: 0.2953 - val_accuracy: 0.9231 - val_loss: 0.2663\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2747 - val_accuracy: 0.9274 - val_loss: 0.2503\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.2560 - val_accuracy: 0.9289 - val_loss: 0.2416\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9314 - loss: 0.2371 - val_accuracy: 0.9348 - val_loss: 0.2223\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9366 - loss: 0.2207 - val_accuracy: 0.9394 - val_loss: 0.2103\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9401 - loss: 0.2047 - val_accuracy: 0.9448 - val_loss: 0.1950\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9431 - loss: 0.1913 - val_accuracy: 0.9429 - val_loss: 0.1985\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.1787 - val_accuracy: 0.9472 - val_loss: 0.1810\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9512 - loss: 0.1654 - val_accuracy: 0.9507 - val_loss: 0.1686\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9533 - loss: 0.1553 - val_accuracy: 0.9528 - val_loss: 0.1600\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6221 - loss: 1.2241 - val_accuracy: 0.8322 - val_loss: 0.6022\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8535 - loss: 0.5071 - val_accuracy: 0.8902 - val_loss: 0.3947\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8864 - loss: 0.3912 - val_accuracy: 0.9016 - val_loss: 0.3421\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8999 - loss: 0.3468 - val_accuracy: 0.9090 - val_loss: 0.3083\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9085 - loss: 0.3161 - val_accuracy: 0.9185 - val_loss: 0.2860\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9154 - loss: 0.2936 - val_accuracy: 0.9229 - val_loss: 0.2669\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2698 - val_accuracy: 0.9270 - val_loss: 0.2496\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9281 - loss: 0.2498 - val_accuracy: 0.9316 - val_loss: 0.2382\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.2330 - val_accuracy: 0.9367 - val_loss: 0.2197\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9379 - loss: 0.2150 - val_accuracy: 0.9414 - val_loss: 0.2042\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9420 - loss: 0.1994 - val_accuracy: 0.9441 - val_loss: 0.1918\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9455 - loss: 0.1864 - val_accuracy: 0.9455 - val_loss: 0.1845\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9498 - loss: 0.1731 - val_accuracy: 0.9502 - val_loss: 0.1731\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9528 - loss: 0.1619 - val_accuracy: 0.9514 - val_loss: 0.1667\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9553 - loss: 0.1531 - val_accuracy: 0.9557 - val_loss: 0.1575\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9571 - loss: 0.1432 - val_accuracy: 0.9572 - val_loss: 0.1497\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9602 - loss: 0.1347 - val_accuracy: 0.9579 - val_loss: 0.1436\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9627 - loss: 0.1269 - val_accuracy: 0.9602 - val_loss: 0.1376\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9650 - loss: 0.1194 - val_accuracy: 0.9605 - val_loss: 0.1343\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9672 - loss: 0.1126 - val_accuracy: 0.9613 - val_loss: 0.1293\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9342 - accuracy: 0.6319 - loss: 1.2003 - val_TopKCategoricalAccuracy: 0.9884 - val_accuracy: 0.8422 - val_loss: 0.5697\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9911 - accuracy: 0.8607 - loss: 0.4775 - val_TopKCategoricalAccuracy: 0.9933 - val_accuracy: 0.8921 - val_loss: 0.3799\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9940 - accuracy: 0.8927 - loss: 0.3737 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9023 - val_loss: 0.3298\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.9038 - loss: 0.3366 - val_TopKCategoricalAccuracy: 0.9949 - val_accuracy: 0.9108 - val_loss: 0.3036\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9094 - loss: 0.3136 - val_TopKCategoricalAccuracy: 0.9952 - val_accuracy: 0.9177 - val_loss: 0.2851\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9336 - accuracy: 0.6465 - loss: 1.1937 - val_TopKCategoricalAccuracy: 0.9893 - val_accuracy: 0.8454 - val_loss: 0.5574\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9917 - accuracy: 0.8670 - loss: 0.4645 - val_TopKCategoricalAccuracy: 0.9932 - val_accuracy: 0.8929 - val_loss: 0.3794\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9944 - accuracy: 0.8935 - loss: 0.3686 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.9048 - val_loss: 0.3300\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9949 - accuracy: 0.9049 - loss: 0.3311 - val_TopKCategoricalAccuracy: 0.9950 - val_accuracy: 0.9126 - val_loss: 0.2983\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9126 - loss: 0.3042 - val_TopKCategoricalAccuracy: 0.9951 - val_accuracy: 0.9207 - val_loss: 0.2745\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9961 - accuracy: 0.9187 - loss: 0.2817 - val_TopKCategoricalAccuracy: 0.9956 - val_accuracy: 0.9258 - val_loss: 0.2562\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9962 - accuracy: 0.9244 - loss: 0.2615 - val_TopKCategoricalAccuracy: 0.9960 - val_accuracy: 0.9314 - val_loss: 0.2379\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9968 - accuracy: 0.9294 - loss: 0.2416 - val_TopKCategoricalAccuracy: 0.9962 - val_accuracy: 0.9362 - val_loss: 0.2215\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9972 - accuracy: 0.9351 - loss: 0.2241 - val_TopKCategoricalAccuracy: 0.9964 - val_accuracy: 0.9398 - val_loss: 0.2104\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9975 - accuracy: 0.9391 - loss: 0.2084 - val_TopKCategoricalAccuracy: 0.9964 - val_accuracy: 0.9441 - val_loss: 0.2007\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - TopKCategoricalAccuracy: 0.9395 - accuracy: 0.6631 - loss: 1.1685 - val_TopKCategoricalAccuracy: 0.9887 - val_accuracy: 0.8519 - val_loss: 0.5371\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9911 - accuracy: 0.8696 - loss: 0.4589 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.8891 - val_loss: 0.3792\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9938 - accuracy: 0.8914 - loss: 0.3744 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9018 - val_loss: 0.3323\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9947 - accuracy: 0.9032 - loss: 0.3361 - val_TopKCategoricalAccuracy: 0.9952 - val_accuracy: 0.9129 - val_loss: 0.2996\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9118 - loss: 0.3083 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9202 - val_loss: 0.2785\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9960 - accuracy: 0.9174 - loss: 0.2857 - val_TopKCategoricalAccuracy: 0.9955 - val_accuracy: 0.9239 - val_loss: 0.2608\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9964 - accuracy: 0.9240 - loss: 0.2631 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9299 - val_loss: 0.2439\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9968 - accuracy: 0.9284 - loss: 0.2445 - val_TopKCategoricalAccuracy: 0.9964 - val_accuracy: 0.9359 - val_loss: 0.2252\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9970 - accuracy: 0.9336 - loss: 0.2275 - val_TopKCategoricalAccuracy: 0.9964 - val_accuracy: 0.9384 - val_loss: 0.2157\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9973 - accuracy: 0.9382 - loss: 0.2111 - val_TopKCategoricalAccuracy: 0.9962 - val_accuracy: 0.9412 - val_loss: 0.2041\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9976 - accuracy: 0.9418 - loss: 0.1977 - val_TopKCategoricalAccuracy: 0.9973 - val_accuracy: 0.9462 - val_loss: 0.1882\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9979 - accuracy: 0.9461 - loss: 0.1844 - val_TopKCategoricalAccuracy: 0.9978 - val_accuracy: 0.9489 - val_loss: 0.1776\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - TopKCategoricalAccuracy: 0.9979 - accuracy: 0.9487 - loss: 0.1738 - val_TopKCategoricalAccuracy: 0.9980 - val_accuracy: 0.9505 - val_loss: 0.1717\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - TopKCategoricalAccuracy: 0.9981 - accuracy: 0.9524 - loss: 0.1623 - val_TopKCategoricalAccuracy: 0.9977 - val_accuracy: 0.9525 - val_loss: 0.1669\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9983 - accuracy: 0.9549 - loss: 0.1532 - val_TopKCategoricalAccuracy: 0.9977 - val_accuracy: 0.9549 - val_loss: 0.1597\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - TopKCategoricalAccuracy: 0.9228 - accuracy: 0.6261 - loss: 1.2255 - val_TopKCategoricalAccuracy: 0.9873 - val_accuracy: 0.8359 - val_loss: 0.6011\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9902 - accuracy: 0.8513 - loss: 0.5083 - val_TopKCategoricalAccuracy: 0.9925 - val_accuracy: 0.8799 - val_loss: 0.4148\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9932 - accuracy: 0.8867 - loss: 0.3940 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9010 - val_loss: 0.3439\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9945 - accuracy: 0.9005 - loss: 0.3490 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9118 - val_loss: 0.3087\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9088 - loss: 0.3188 - val_TopKCategoricalAccuracy: 0.9955 - val_accuracy: 0.9175 - val_loss: 0.2854\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9145 - loss: 0.2943 - val_TopKCategoricalAccuracy: 0.9953 - val_accuracy: 0.9238 - val_loss: 0.2718\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9962 - accuracy: 0.9205 - loss: 0.2746 - val_TopKCategoricalAccuracy: 0.9957 - val_accuracy: 0.9275 - val_loss: 0.2498\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9964 - accuracy: 0.9250 - loss: 0.2580 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9312 - val_loss: 0.2370\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9968 - accuracy: 0.9292 - loss: 0.2422 - val_TopKCategoricalAccuracy: 0.9962 - val_accuracy: 0.9337 - val_loss: 0.2300\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9969 - accuracy: 0.9339 - loss: 0.2262 - val_TopKCategoricalAccuracy: 0.9964 - val_accuracy: 0.9362 - val_loss: 0.2204\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9971 - accuracy: 0.9373 - loss: 0.2134 - val_TopKCategoricalAccuracy: 0.9968 - val_accuracy: 0.9434 - val_loss: 0.2000\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9975 - accuracy: 0.9409 - loss: 0.2004 - val_TopKCategoricalAccuracy: 0.9967 - val_accuracy: 0.9457 - val_loss: 0.1960\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9977 - accuracy: 0.9451 - loss: 0.1871 - val_TopKCategoricalAccuracy: 0.9974 - val_accuracy: 0.9467 - val_loss: 0.1848\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9979 - accuracy: 0.9482 - loss: 0.1757 - val_TopKCategoricalAccuracy: 0.9976 - val_accuracy: 0.9499 - val_loss: 0.1744\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9983 - accuracy: 0.9516 - loss: 0.1651 - val_TopKCategoricalAccuracy: 0.9973 - val_accuracy: 0.9515 - val_loss: 0.1705\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9984 - accuracy: 0.9549 - loss: 0.1561 - val_TopKCategoricalAccuracy: 0.9981 - val_accuracy: 0.9524 - val_loss: 0.1610\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9986 - accuracy: 0.9564 - loss: 0.1470 - val_TopKCategoricalAccuracy: 0.9980 - val_accuracy: 0.9540 - val_loss: 0.1557\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9988 - accuracy: 0.9583 - loss: 0.1386 - val_TopKCategoricalAccuracy: 0.9983 - val_accuracy: 0.9561 - val_loss: 0.1482\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9989 - accuracy: 0.9617 - loss: 0.1306 - val_TopKCategoricalAccuracy: 0.9979 - val_accuracy: 0.9565 - val_loss: 0.1484\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9990 - accuracy: 0.9638 - loss: 0.1234 - val_TopKCategoricalAccuracy: 0.9985 - val_accuracy: 0.9589 - val_loss: 0.1403\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1222 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1135 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2987 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2984 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2983 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1244 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2984 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2984 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2982 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2981 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2980 - val_accuracy: 0.1060 - val_loss: 2.2990\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2979 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2978 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2976 - val_accuracy: 0.1060 - val_loss: 2.2986\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2975 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2974 - val_accuracy: 0.1060 - val_loss: 2.2984\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2973 - val_accuracy: 0.1060 - val_loss: 2.2982\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1179 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2987 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2984 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2982 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2981 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2980 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2978 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2977 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2976 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2975 - val_accuracy: 0.1060 - val_loss: 2.2983\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2973 - val_accuracy: 0.1060 - val_loss: 2.2982\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2972 - val_accuracy: 0.1060 - val_loss: 2.2980\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2971 - val_accuracy: 0.1060 - val_loss: 2.2979\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2969 - val_accuracy: 0.1060 - val_loss: 2.2978\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2967 - val_accuracy: 0.1060 - val_loss: 2.2978\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2966 - val_accuracy: 0.1060 - val_loss: 2.2975\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2964 - val_accuracy: 0.1060 - val_loss: 2.2974\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5507 - accuracy: 0.1196 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5121 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5371 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5125 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5426 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5972 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5453 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.5625 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5507 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.6176 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5996 - accuracy: 0.1155 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5186 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5383 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5477 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5542 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5533 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5488 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5635 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5634 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5577 - accuracy: 0.1140 - loss: 2.2983 - val_TopKCategoricalAccuracy: 0.5655 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5716 - accuracy: 0.1140 - loss: 2.2981 - val_TopKCategoricalAccuracy: 0.5547 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5571 - accuracy: 0.1140 - loss: 2.2980 - val_TopKCategoricalAccuracy: 0.5658 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5787 - accuracy: 0.1140 - loss: 2.2979 - val_TopKCategoricalAccuracy: 0.6061 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5853 - accuracy: 0.1140 - loss: 2.2977 - val_TopKCategoricalAccuracy: 0.5521 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5669 - accuracy: 0.1201 - loss: 2.3001 - val_TopKCategoricalAccuracy: 0.5717 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5699 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5532 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5469 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5627 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5696 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.5344 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5417 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5462 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5623 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5646 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5537 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5115 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5499 - accuracy: 0.1140 - loss: 2.2983 - val_TopKCategoricalAccuracy: 0.5395 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5644 - accuracy: 0.1140 - loss: 2.2981 - val_TopKCategoricalAccuracy: 0.5844 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5912 - accuracy: 0.1140 - loss: 2.2980 - val_TopKCategoricalAccuracy: 0.6190 - val_accuracy: 0.1060 - val_loss: 2.2990\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5846 - accuracy: 0.1140 - loss: 2.2979 - val_TopKCategoricalAccuracy: 0.6445 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.6006 - accuracy: 0.1140 - loss: 2.2978 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5408 - accuracy: 0.1140 - loss: 2.2977 - val_TopKCategoricalAccuracy: 0.6070 - val_accuracy: 0.1060 - val_loss: 2.2986\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.5570 - accuracy: 0.1140 - loss: 2.2976 - val_TopKCategoricalAccuracy: 0.6042 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - TopKCategoricalAccuracy: 0.5766 - accuracy: 0.1140 - loss: 2.2974 - val_TopKCategoricalAccuracy: 0.5667 - val_accuracy: 0.1060 - val_loss: 2.2984\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - TopKCategoricalAccuracy: 0.5880 - accuracy: 0.1174 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5420 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5724 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5608 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5298 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5310 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5428 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.6777 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.6074 - accuracy: 0.1140 - loss: 2.2983 - val_TopKCategoricalAccuracy: 0.5132 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5541 - accuracy: 0.1140 - loss: 2.2982 - val_TopKCategoricalAccuracy: 0.6275 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5912 - accuracy: 0.1140 - loss: 2.2981 - val_TopKCategoricalAccuracy: 0.6463 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5950 - accuracy: 0.1140 - loss: 2.2980 - val_TopKCategoricalAccuracy: 0.6476 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5948 - accuracy: 0.1140 - loss: 2.2979 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5510 - accuracy: 0.1140 - loss: 2.2977 - val_TopKCategoricalAccuracy: 0.6004 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5632 - accuracy: 0.1140 - loss: 2.2976 - val_TopKCategoricalAccuracy: 0.5636 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5864 - accuracy: 0.1140 - loss: 2.2975 - val_TopKCategoricalAccuracy: 0.6143 - val_accuracy: 0.1060 - val_loss: 2.2984\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5887 - accuracy: 0.1140 - loss: 2.2973 - val_TopKCategoricalAccuracy: 0.6385 - val_accuracy: 0.1060 - val_loss: 2.2983\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.6142 - accuracy: 0.1140 - loss: 2.2972 - val_TopKCategoricalAccuracy: 0.5626 - val_accuracy: 0.1060 - val_loss: 2.2982\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5911 - accuracy: 0.1140 - loss: 2.2971 - val_TopKCategoricalAccuracy: 0.5972 - val_accuracy: 0.1060 - val_loss: 2.2980\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5899 - accuracy: 0.1140 - loss: 2.2969 - val_TopKCategoricalAccuracy: 0.6191 - val_accuracy: 0.1060 - val_loss: 2.2979\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5944 - accuracy: 0.1140 - loss: 2.2968 - val_TopKCategoricalAccuracy: 0.6799 - val_accuracy: 0.1060 - val_loss: 2.2977\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5667 - accuracy: 0.1140 - loss: 2.2966 - val_TopKCategoricalAccuracy: 0.5807 - val_accuracy: 0.1060 - val_loss: 2.2975\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5866 - accuracy: 0.1140 - loss: 2.2965 - val_TopKCategoricalAccuracy: 0.5259 - val_accuracy: 0.1060 - val_loss: 2.2975\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5986 - loss: 1.2877 - val_accuracy: 0.8391 - val_loss: 0.5977\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.5692 - val_accuracy: 0.8886 - val_loss: 0.3900\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8676 - loss: 0.4445 - val_accuracy: 0.9046 - val_loss: 0.3290\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8882 - loss: 0.3813 - val_accuracy: 0.9144 - val_loss: 0.2886\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8993 - loss: 0.3381 - val_accuracy: 0.9223 - val_loss: 0.2594\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6100 - loss: 1.2790 - val_accuracy: 0.8408 - val_loss: 0.5750\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8295 - loss: 0.5568 - val_accuracy: 0.8924 - val_loss: 0.3800\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8710 - loss: 0.4332 - val_accuracy: 0.9050 - val_loss: 0.3231\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8891 - loss: 0.3706 - val_accuracy: 0.9174 - val_loss: 0.2802\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9034 - loss: 0.3283 - val_accuracy: 0.9244 - val_loss: 0.2467\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.2963 - val_accuracy: 0.9323 - val_loss: 0.2242\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2720 - val_accuracy: 0.9389 - val_loss: 0.2040\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9266 - loss: 0.2465 - val_accuracy: 0.9436 - val_loss: 0.1883\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9330 - loss: 0.2267 - val_accuracy: 0.9455 - val_loss: 0.1798\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9374 - loss: 0.2111 - val_accuracy: 0.9514 - val_loss: 0.1665\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.5682 - loss: 1.3282 - val_accuracy: 0.8240 - val_loss: 0.6423\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8149 - loss: 0.5997 - val_accuracy: 0.8876 - val_loss: 0.4055\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8629 - loss: 0.4544 - val_accuracy: 0.9060 - val_loss: 0.3329\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8836 - loss: 0.3943 - val_accuracy: 0.9142 - val_loss: 0.2935\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8956 - loss: 0.3491 - val_accuracy: 0.9217 - val_loss: 0.2663\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9063 - loss: 0.3188 - val_accuracy: 0.9283 - val_loss: 0.2416\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9133 - loss: 0.2907 - val_accuracy: 0.9334 - val_loss: 0.2201\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9203 - loss: 0.2674 - val_accuracy: 0.9401 - val_loss: 0.2032\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9266 - loss: 0.2490 - val_accuracy: 0.9435 - val_loss: 0.1907\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9324 - loss: 0.2305 - val_accuracy: 0.9492 - val_loss: 0.1766\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.2143 - val_accuracy: 0.9497 - val_loss: 0.1661\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9401 - loss: 0.2012 - val_accuracy: 0.9537 - val_loss: 0.1558\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9434 - loss: 0.1890 - val_accuracy: 0.9557 - val_loss: 0.1502\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9468 - loss: 0.1790 - val_accuracy: 0.9597 - val_loss: 0.1407\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9483 - loss: 0.1697 - val_accuracy: 0.9592 - val_loss: 0.1355\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.5806 - loss: 1.3103 - val_accuracy: 0.8365 - val_loss: 0.6126\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8257 - loss: 0.5702 - val_accuracy: 0.8928 - val_loss: 0.3778\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8701 - loss: 0.4346 - val_accuracy: 0.9069 - val_loss: 0.3179\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8887 - loss: 0.3746 - val_accuracy: 0.9143 - val_loss: 0.2826\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 0.3310 - val_accuracy: 0.9231 - val_loss: 0.2567\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.3008 - val_accuracy: 0.9306 - val_loss: 0.2308\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2745 - val_accuracy: 0.9366 - val_loss: 0.2117\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9260 - loss: 0.2493 - val_accuracy: 0.9402 - val_loss: 0.1974\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9300 - loss: 0.2330 - val_accuracy: 0.9468 - val_loss: 0.1785\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9356 - loss: 0.2166 - val_accuracy: 0.9477 - val_loss: 0.1729\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9399 - loss: 0.2010 - val_accuracy: 0.9536 - val_loss: 0.1581\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9442 - loss: 0.1868 - val_accuracy: 0.9564 - val_loss: 0.1503\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9471 - loss: 0.1771 - val_accuracy: 0.9569 - val_loss: 0.1452\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9505 - loss: 0.1661 - val_accuracy: 0.9614 - val_loss: 0.1350\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9523 - loss: 0.1577 - val_accuracy: 0.9623 - val_loss: 0.1283\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9546 - loss: 0.1521 - val_accuracy: 0.9638 - val_loss: 0.1252\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9566 - loss: 0.1443 - val_accuracy: 0.9648 - val_loss: 0.1211\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9593 - loss: 0.1381 - val_accuracy: 0.9655 - val_loss: 0.1166\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9609 - loss: 0.1301 - val_accuracy: 0.9657 - val_loss: 0.1137\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9623 - loss: 0.1243 - val_accuracy: 0.9676 - val_loss: 0.1107\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9291 - accuracy: 0.6093 - loss: 1.2762 - val_TopKCategoricalAccuracy: 0.9894 - val_accuracy: 0.8529 - val_loss: 0.5529\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9900 - accuracy: 0.8305 - loss: 0.5492 - val_TopKCategoricalAccuracy: 0.9935 - val_accuracy: 0.8928 - val_loss: 0.3827\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9927 - accuracy: 0.8693 - loss: 0.4402 - val_TopKCategoricalAccuracy: 0.9945 - val_accuracy: 0.9033 - val_loss: 0.3266\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9936 - accuracy: 0.8894 - loss: 0.3799 - val_TopKCategoricalAccuracy: 0.9951 - val_accuracy: 0.9128 - val_loss: 0.2899\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.8997 - loss: 0.3393 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9192 - val_loss: 0.2627\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9346 - accuracy: 0.6185 - loss: 1.2710 - val_TopKCategoricalAccuracy: 0.9893 - val_accuracy: 0.8453 - val_loss: 0.5626\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9899 - accuracy: 0.8313 - loss: 0.5490 - val_TopKCategoricalAccuracy: 0.9933 - val_accuracy: 0.8907 - val_loss: 0.3825\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9933 - accuracy: 0.8721 - loss: 0.4283 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9102 - val_loss: 0.3163\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9944 - accuracy: 0.8890 - loss: 0.3707 - val_TopKCategoricalAccuracy: 0.9950 - val_accuracy: 0.9187 - val_loss: 0.2790\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9034 - loss: 0.3275 - val_TopKCategoricalAccuracy: 0.9957 - val_accuracy: 0.9252 - val_loss: 0.2515\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9953 - accuracy: 0.9109 - loss: 0.2987 - val_TopKCategoricalAccuracy: 0.9962 - val_accuracy: 0.9331 - val_loss: 0.2283\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9962 - accuracy: 0.9175 - loss: 0.2732 - val_TopKCategoricalAccuracy: 0.9967 - val_accuracy: 0.9388 - val_loss: 0.2078\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9965 - accuracy: 0.9255 - loss: 0.2497 - val_TopKCategoricalAccuracy: 0.9969 - val_accuracy: 0.9423 - val_loss: 0.1936\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9973 - accuracy: 0.9311 - loss: 0.2304 - val_TopKCategoricalAccuracy: 0.9973 - val_accuracy: 0.9486 - val_loss: 0.1808\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9974 - accuracy: 0.9374 - loss: 0.2134 - val_TopKCategoricalAccuracy: 0.9977 - val_accuracy: 0.9513 - val_loss: 0.1668\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9137 - accuracy: 0.5673 - loss: 1.3063 - val_TopKCategoricalAccuracy: 0.9902 - val_accuracy: 0.8388 - val_loss: 0.5876\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9889 - accuracy: 0.8219 - loss: 0.5745 - val_TopKCategoricalAccuracy: 0.9938 - val_accuracy: 0.8876 - val_loss: 0.3946\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9920 - accuracy: 0.8660 - loss: 0.4460 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9042 - val_loss: 0.3274\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9941 - accuracy: 0.8853 - loss: 0.3847 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9122 - val_loss: 0.2913\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9949 - accuracy: 0.8973 - loss: 0.3437 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9231 - val_loss: 0.2622\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9094 - loss: 0.3087 - val_TopKCategoricalAccuracy: 0.9965 - val_accuracy: 0.9294 - val_loss: 0.2335\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9960 - accuracy: 0.9162 - loss: 0.2832 - val_TopKCategoricalAccuracy: 0.9964 - val_accuracy: 0.9348 - val_loss: 0.2158\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9965 - accuracy: 0.9227 - loss: 0.2601 - val_TopKCategoricalAccuracy: 0.9967 - val_accuracy: 0.9398 - val_loss: 0.2016\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9966 - accuracy: 0.9284 - loss: 0.2412 - val_TopKCategoricalAccuracy: 0.9973 - val_accuracy: 0.9453 - val_loss: 0.1850\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9970 - accuracy: 0.9334 - loss: 0.2235 - val_TopKCategoricalAccuracy: 0.9974 - val_accuracy: 0.9489 - val_loss: 0.1721\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9974 - accuracy: 0.9375 - loss: 0.2086 - val_TopKCategoricalAccuracy: 0.9974 - val_accuracy: 0.9523 - val_loss: 0.1606\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9977 - accuracy: 0.9424 - loss: 0.1954 - val_TopKCategoricalAccuracy: 0.9980 - val_accuracy: 0.9564 - val_loss: 0.1507\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9977 - accuracy: 0.9449 - loss: 0.1843 - val_TopKCategoricalAccuracy: 0.9981 - val_accuracy: 0.9578 - val_loss: 0.1446\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9982 - accuracy: 0.9472 - loss: 0.1735 - val_TopKCategoricalAccuracy: 0.9980 - val_accuracy: 0.9588 - val_loss: 0.1370\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9982 - accuracy: 0.9505 - loss: 0.1653 - val_TopKCategoricalAccuracy: 0.9986 - val_accuracy: 0.9603 - val_loss: 0.1311\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9304 - accuracy: 0.5963 - loss: 1.3001 - val_TopKCategoricalAccuracy: 0.9883 - val_accuracy: 0.8450 - val_loss: 0.5809\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9894 - accuracy: 0.8247 - loss: 0.5678 - val_TopKCategoricalAccuracy: 0.9929 - val_accuracy: 0.8901 - val_loss: 0.3846\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9927 - accuracy: 0.8678 - loss: 0.4381 - val_TopKCategoricalAccuracy: 0.9941 - val_accuracy: 0.9051 - val_loss: 0.3235\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9942 - accuracy: 0.8864 - loss: 0.3792 - val_TopKCategoricalAccuracy: 0.9951 - val_accuracy: 0.9162 - val_loss: 0.2849\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.8999 - loss: 0.3342 - val_TopKCategoricalAccuracy: 0.9956 - val_accuracy: 0.9244 - val_loss: 0.2541\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9117 - loss: 0.3012 - val_TopKCategoricalAccuracy: 0.9962 - val_accuracy: 0.9308 - val_loss: 0.2308\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9960 - accuracy: 0.9185 - loss: 0.2735 - val_TopKCategoricalAccuracy: 0.9967 - val_accuracy: 0.9381 - val_loss: 0.2081\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9966 - accuracy: 0.9262 - loss: 0.2494 - val_TopKCategoricalAccuracy: 0.9968 - val_accuracy: 0.9442 - val_loss: 0.1903\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9969 - accuracy: 0.9304 - loss: 0.2356 - val_TopKCategoricalAccuracy: 0.9973 - val_accuracy: 0.9480 - val_loss: 0.1762\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9974 - accuracy: 0.9367 - loss: 0.2161 - val_TopKCategoricalAccuracy: 0.9977 - val_accuracy: 0.9503 - val_loss: 0.1672\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9977 - accuracy: 0.9406 - loss: 0.1994 - val_TopKCategoricalAccuracy: 0.9978 - val_accuracy: 0.9534 - val_loss: 0.1554\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9976 - accuracy: 0.9439 - loss: 0.1910 - val_TopKCategoricalAccuracy: 0.9977 - val_accuracy: 0.9532 - val_loss: 0.1518\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9981 - accuracy: 0.9477 - loss: 0.1780 - val_TopKCategoricalAccuracy: 0.9978 - val_accuracy: 0.9589 - val_loss: 0.1388\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9982 - accuracy: 0.9509 - loss: 0.1675 - val_TopKCategoricalAccuracy: 0.9980 - val_accuracy: 0.9611 - val_loss: 0.1323\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9982 - accuracy: 0.9517 - loss: 0.1601 - val_TopKCategoricalAccuracy: 0.9982 - val_accuracy: 0.9625 - val_loss: 0.1266\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9984 - accuracy: 0.9538 - loss: 0.1541 - val_TopKCategoricalAccuracy: 0.9984 - val_accuracy: 0.9628 - val_loss: 0.1243\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9985 - accuracy: 0.9572 - loss: 0.1445 - val_TopKCategoricalAccuracy: 0.9983 - val_accuracy: 0.9632 - val_loss: 0.1183\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9987 - accuracy: 0.9584 - loss: 0.1388 - val_TopKCategoricalAccuracy: 0.9983 - val_accuracy: 0.9655 - val_loss: 0.1147\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9989 - accuracy: 0.9585 - loss: 0.1339 - val_TopKCategoricalAccuracy: 0.9985 - val_accuracy: 0.9666 - val_loss: 0.1110\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9990 - accuracy: 0.9606 - loss: 0.1285 - val_TopKCategoricalAccuracy: 0.9986 - val_accuracy: 0.9658 - val_loss: 0.1128\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1145 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1238 - loss: 2.3002 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2983 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2981 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2980 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2979 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2979 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1213 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2987 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2987 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2983 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2982 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2980 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2981 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2978 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2977 - val_accuracy: 0.1060 - val_loss: 2.2986\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1164 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2987 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2984 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2983 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2981 - val_accuracy: 0.1060 - val_loss: 2.2990\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2980 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2980 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2978 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2978 - val_accuracy: 0.1060 - val_loss: 2.2986\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2977 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2975 - val_accuracy: 0.1060 - val_loss: 2.2984\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2974 - val_accuracy: 0.1060 - val_loss: 2.2982\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2972 - val_accuracy: 0.1060 - val_loss: 2.2981\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5532 - accuracy: 0.1156 - loss: 2.3004 - val_TopKCategoricalAccuracy: 0.5527 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5433 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5222 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5376 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5327 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5465 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5256 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5496 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5264 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5673 - accuracy: 0.1267 - loss: 2.3006 - val_TopKCategoricalAccuracy: 0.5856 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5613 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5328 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5485 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5989 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5451 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5379 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5406 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5317 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5429 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5397 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5430 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.5183 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5510 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.5319 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5492 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5518 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5513 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5982 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5703 - accuracy: 0.1149 - loss: 2.3004 - val_TopKCategoricalAccuracy: 0.5218 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5507 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5136 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5507 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5110 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5471 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5343 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5458 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.6498 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5537 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5131 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5490 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5822 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5539 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5160 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5536 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5170 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5539 - accuracy: 0.1140 - loss: 2.2982 - val_TopKCategoricalAccuracy: 0.5701 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5474 - accuracy: 0.1140 - loss: 2.2981 - val_TopKCategoricalAccuracy: 0.6053 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5562 - accuracy: 0.1140 - loss: 2.2981 - val_TopKCategoricalAccuracy: 0.5559 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5589 - accuracy: 0.1140 - loss: 2.2979 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5578 - accuracy: 0.1140 - loss: 2.2979 - val_TopKCategoricalAccuracy: 0.5135 - val_accuracy: 0.1060 - val_loss: 2.2986\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5601 - accuracy: 0.1140 - loss: 2.2976 - val_TopKCategoricalAccuracy: 0.5199 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Testing: hidden_units=[256, 128], activation=relu, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5528 - accuracy: 0.1154 - loss: 2.3006 - val_TopKCategoricalAccuracy: 0.5468 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5402 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5546 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5358 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5376 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5387 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5112 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5355 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5458 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5364 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5127 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5394 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5529 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5364 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5142 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5473 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5645 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5449 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5239 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5475 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5133 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5404 - accuracy: 0.1140 - loss: 2.2983 - val_TopKCategoricalAccuracy: 0.5807 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5454 - accuracy: 0.1140 - loss: 2.2982 - val_TopKCategoricalAccuracy: 0.5905 - val_accuracy: 0.1060 - val_loss: 2.2990\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5452 - accuracy: 0.1140 - loss: 2.2981 - val_TopKCategoricalAccuracy: 0.5930 - val_accuracy: 0.1060 - val_loss: 2.2990\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5455 - accuracy: 0.1140 - loss: 2.2980 - val_TopKCategoricalAccuracy: 0.6451 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5535 - accuracy: 0.1140 - loss: 2.2979 - val_TopKCategoricalAccuracy: 0.5886 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5557 - accuracy: 0.1140 - loss: 2.2977 - val_TopKCategoricalAccuracy: 0.5763 - val_accuracy: 0.1060 - val_loss: 2.2986\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5576 - accuracy: 0.1140 - loss: 2.2977 - val_TopKCategoricalAccuracy: 0.5854 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5499 - accuracy: 0.1140 - loss: 2.2975 - val_TopKCategoricalAccuracy: 0.6398 - val_accuracy: 0.1060 - val_loss: 2.2984\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5590 - accuracy: 0.1140 - loss: 2.2974 - val_TopKCategoricalAccuracy: 0.5797 - val_accuracy: 0.1060 - val_loss: 2.2983\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7191 - loss: 0.9593 - val_accuracy: 0.8858 - val_loss: 0.4076\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8892 - loss: 0.3809 - val_accuracy: 0.9046 - val_loss: 0.3257\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.3258 - val_accuracy: 0.9159 - val_loss: 0.2871\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.3009 - val_accuracy: 0.9224 - val_loss: 0.2729\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9180 - loss: 0.2865 - val_accuracy: 0.9251 - val_loss: 0.2640\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.7160 - loss: 0.9560 - val_accuracy: 0.8843 - val_loss: 0.4094\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8900 - loss: 0.3798 - val_accuracy: 0.9040 - val_loss: 0.3235\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.3246 - val_accuracy: 0.9158 - val_loss: 0.2917\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9125 - loss: 0.3003 - val_accuracy: 0.9197 - val_loss: 0.2800\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.2870 - val_accuracy: 0.9212 - val_loss: 0.2717\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9200 - loss: 0.2784 - val_accuracy: 0.9254 - val_loss: 0.2608\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9220 - loss: 0.2705 - val_accuracy: 0.9270 - val_loss: 0.2590\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9241 - loss: 0.2645 - val_accuracy: 0.9287 - val_loss: 0.2596\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9256 - loss: 0.2589 - val_accuracy: 0.9303 - val_loss: 0.2536\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9272 - loss: 0.2551 - val_accuracy: 0.9324 - val_loss: 0.2490\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7108 - loss: 0.9593 - val_accuracy: 0.8796 - val_loss: 0.4183\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.3814 - val_accuracy: 0.9083 - val_loss: 0.3195\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9061 - loss: 0.3259 - val_accuracy: 0.9151 - val_loss: 0.2920\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.3007 - val_accuracy: 0.9219 - val_loss: 0.2720\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2884 - val_accuracy: 0.9221 - val_loss: 0.2703\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9195 - loss: 0.2795 - val_accuracy: 0.9234 - val_loss: 0.2684\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.2720 - val_accuracy: 0.9220 - val_loss: 0.2704\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9236 - loss: 0.2663 - val_accuracy: 0.9298 - val_loss: 0.2537\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9249 - loss: 0.2619 - val_accuracy: 0.9285 - val_loss: 0.2535\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9270 - loss: 0.2552 - val_accuracy: 0.9285 - val_loss: 0.2501\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9288 - loss: 0.2510 - val_accuracy: 0.9316 - val_loss: 0.2434\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9300 - loss: 0.2441 - val_accuracy: 0.9310 - val_loss: 0.2442\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9293 - loss: 0.2412 - val_accuracy: 0.9350 - val_loss: 0.2348\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9327 - loss: 0.2336 - val_accuracy: 0.9319 - val_loss: 0.2391\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9333 - loss: 0.2292 - val_accuracy: 0.9324 - val_loss: 0.2360\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.7090 - loss: 0.9682 - val_accuracy: 0.8773 - val_loss: 0.4243\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8899 - loss: 0.3823 - val_accuracy: 0.9048 - val_loss: 0.3245\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9061 - loss: 0.3251 - val_accuracy: 0.9168 - val_loss: 0.2926\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2996 - val_accuracy: 0.9184 - val_loss: 0.2786\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9179 - loss: 0.2852 - val_accuracy: 0.9243 - val_loss: 0.2683\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9202 - loss: 0.2792 - val_accuracy: 0.9276 - val_loss: 0.2601\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9215 - loss: 0.2715 - val_accuracy: 0.9262 - val_loss: 0.2599\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9245 - loss: 0.2656 - val_accuracy: 0.9300 - val_loss: 0.2520\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9254 - loss: 0.2596 - val_accuracy: 0.9283 - val_loss: 0.2540\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9263 - loss: 0.2559 - val_accuracy: 0.9302 - val_loss: 0.2494\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9292 - loss: 0.2498 - val_accuracy: 0.9323 - val_loss: 0.2436\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9301 - loss: 0.2440 - val_accuracy: 0.9323 - val_loss: 0.2393\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9318 - loss: 0.2371 - val_accuracy: 0.9339 - val_loss: 0.2359\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9324 - loss: 0.2330 - val_accuracy: 0.9359 - val_loss: 0.2285\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9349 - loss: 0.2270 - val_accuracy: 0.9368 - val_loss: 0.2277\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9354 - loss: 0.2221 - val_accuracy: 0.9378 - val_loss: 0.2232\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9363 - loss: 0.2171 - val_accuracy: 0.9367 - val_loss: 0.2241\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9384 - loss: 0.2114 - val_accuracy: 0.9390 - val_loss: 0.2191\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9398 - loss: 0.2068 - val_accuracy: 0.9392 - val_loss: 0.2132\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9403 - loss: 0.2030 - val_accuracy: 0.9416 - val_loss: 0.2062\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9498 - accuracy: 0.7117 - loss: 0.9628 - val_TopKCategoricalAccuracy: 0.9921 - val_accuracy: 0.8831 - val_loss: 0.4154\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9934 - accuracy: 0.8889 - loss: 0.3818 - val_TopKCategoricalAccuracy: 0.9947 - val_accuracy: 0.9053 - val_loss: 0.3273\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9945 - accuracy: 0.9065 - loss: 0.3263 - val_TopKCategoricalAccuracy: 0.9949 - val_accuracy: 0.9162 - val_loss: 0.2940\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9953 - accuracy: 0.9133 - loss: 0.3025 - val_TopKCategoricalAccuracy: 0.9947 - val_accuracy: 0.9207 - val_loss: 0.2824\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9165 - loss: 0.2889 - val_TopKCategoricalAccuracy: 0.9949 - val_accuracy: 0.9237 - val_loss: 0.2702\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9530 - accuracy: 0.7337 - loss: 0.9426 - val_TopKCategoricalAccuracy: 0.9922 - val_accuracy: 0.8823 - val_loss: 0.4068\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9936 - accuracy: 0.8905 - loss: 0.3798 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9028 - val_loss: 0.3276\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9047 - loss: 0.3301 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9137 - val_loss: 0.2960\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9136 - loss: 0.3043 - val_TopKCategoricalAccuracy: 0.9951 - val_accuracy: 0.9185 - val_loss: 0.2792\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9172 - loss: 0.2887 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9227 - val_loss: 0.2697\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9959 - accuracy: 0.9205 - loss: 0.2776 - val_TopKCategoricalAccuracy: 0.9961 - val_accuracy: 0.9230 - val_loss: 0.2651\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9960 - accuracy: 0.9225 - loss: 0.2701 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9269 - val_loss: 0.2562\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9962 - accuracy: 0.9233 - loss: 0.2645 - val_TopKCategoricalAccuracy: 0.9957 - val_accuracy: 0.9286 - val_loss: 0.2546\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9961 - accuracy: 0.9257 - loss: 0.2587 - val_TopKCategoricalAccuracy: 0.9960 - val_accuracy: 0.9293 - val_loss: 0.2520\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9962 - accuracy: 0.9275 - loss: 0.2515 - val_TopKCategoricalAccuracy: 0.9961 - val_accuracy: 0.9329 - val_loss: 0.2436\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9468 - accuracy: 0.7133 - loss: 0.9596 - val_TopKCategoricalAccuracy: 0.9918 - val_accuracy: 0.8811 - val_loss: 0.4189\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9934 - accuracy: 0.8885 - loss: 0.3834 - val_TopKCategoricalAccuracy: 0.9940 - val_accuracy: 0.9041 - val_loss: 0.3254\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9948 - accuracy: 0.9061 - loss: 0.3301 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9153 - val_loss: 0.2960\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9954 - accuracy: 0.9136 - loss: 0.3038 - val_TopKCategoricalAccuracy: 0.9950 - val_accuracy: 0.9150 - val_loss: 0.2903\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9958 - accuracy: 0.9178 - loss: 0.2882 - val_TopKCategoricalAccuracy: 0.9953 - val_accuracy: 0.9248 - val_loss: 0.2677\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9958 - accuracy: 0.9205 - loss: 0.2790 - val_TopKCategoricalAccuracy: 0.9956 - val_accuracy: 0.9233 - val_loss: 0.2635\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9959 - accuracy: 0.9219 - loss: 0.2709 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9248 - val_loss: 0.2588\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9962 - accuracy: 0.9238 - loss: 0.2646 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9289 - val_loss: 0.2553\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9962 - accuracy: 0.9256 - loss: 0.2599 - val_TopKCategoricalAccuracy: 0.9960 - val_accuracy: 0.9302 - val_loss: 0.2494\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9964 - accuracy: 0.9266 - loss: 0.2528 - val_TopKCategoricalAccuracy: 0.9966 - val_accuracy: 0.9305 - val_loss: 0.2469\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9965 - accuracy: 0.9284 - loss: 0.2464 - val_TopKCategoricalAccuracy: 0.9962 - val_accuracy: 0.9342 - val_loss: 0.2419\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9967 - accuracy: 0.9303 - loss: 0.2403 - val_TopKCategoricalAccuracy: 0.9966 - val_accuracy: 0.9348 - val_loss: 0.2347\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9970 - accuracy: 0.9320 - loss: 0.2342 - val_TopKCategoricalAccuracy: 0.9968 - val_accuracy: 0.9352 - val_loss: 0.2342\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9970 - accuracy: 0.9332 - loss: 0.2285 - val_TopKCategoricalAccuracy: 0.9968 - val_accuracy: 0.9300 - val_loss: 0.2374\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9970 - accuracy: 0.9346 - loss: 0.2237 - val_TopKCategoricalAccuracy: 0.9972 - val_accuracy: 0.9350 - val_loss: 0.2239\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9548 - accuracy: 0.7317 - loss: 0.9444 - val_TopKCategoricalAccuracy: 0.9927 - val_accuracy: 0.8891 - val_loss: 0.3944\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9940 - accuracy: 0.8938 - loss: 0.3676 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9080 - val_loss: 0.3140\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9949 - accuracy: 0.9066 - loss: 0.3224 - val_TopKCategoricalAccuracy: 0.9946 - val_accuracy: 0.9141 - val_loss: 0.2945\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9142 - loss: 0.3017 - val_TopKCategoricalAccuracy: 0.9947 - val_accuracy: 0.9203 - val_loss: 0.2801\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9957 - accuracy: 0.9182 - loss: 0.2869 - val_TopKCategoricalAccuracy: 0.9953 - val_accuracy: 0.9237 - val_loss: 0.2663\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9958 - accuracy: 0.9200 - loss: 0.2810 - val_TopKCategoricalAccuracy: 0.9952 - val_accuracy: 0.9266 - val_loss: 0.2609\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9962 - accuracy: 0.9219 - loss: 0.2724 - val_TopKCategoricalAccuracy: 0.9959 - val_accuracy: 0.9245 - val_loss: 0.2632\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9961 - accuracy: 0.9241 - loss: 0.2659 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9262 - val_loss: 0.2609\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9963 - accuracy: 0.9248 - loss: 0.2592 - val_TopKCategoricalAccuracy: 0.9957 - val_accuracy: 0.9247 - val_loss: 0.2662\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9963 - accuracy: 0.9270 - loss: 0.2545 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9298 - val_loss: 0.2508\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9963 - accuracy: 0.9282 - loss: 0.2487 - val_TopKCategoricalAccuracy: 0.9962 - val_accuracy: 0.9327 - val_loss: 0.2419\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9965 - accuracy: 0.9308 - loss: 0.2424 - val_TopKCategoricalAccuracy: 0.9964 - val_accuracy: 0.9340 - val_loss: 0.2377\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9966 - accuracy: 0.9318 - loss: 0.2374 - val_TopKCategoricalAccuracy: 0.9964 - val_accuracy: 0.9306 - val_loss: 0.2434\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9967 - accuracy: 0.9329 - loss: 0.2324 - val_TopKCategoricalAccuracy: 0.9964 - val_accuracy: 0.9340 - val_loss: 0.2310\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9969 - accuracy: 0.9343 - loss: 0.2261 - val_TopKCategoricalAccuracy: 0.9972 - val_accuracy: 0.9348 - val_loss: 0.2273\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9971 - accuracy: 0.9356 - loss: 0.2208 - val_TopKCategoricalAccuracy: 0.9969 - val_accuracy: 0.9371 - val_loss: 0.2221\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9972 - accuracy: 0.9363 - loss: 0.2166 - val_TopKCategoricalAccuracy: 0.9966 - val_accuracy: 0.9320 - val_loss: 0.2332\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9971 - accuracy: 0.9379 - loss: 0.2118 - val_TopKCategoricalAccuracy: 0.9974 - val_accuracy: 0.9383 - val_loss: 0.2179\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9974 - accuracy: 0.9382 - loss: 0.2073 - val_TopKCategoricalAccuracy: 0.9974 - val_accuracy: 0.9370 - val_loss: 0.2145\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9977 - accuracy: 0.9400 - loss: 0.2031 - val_TopKCategoricalAccuracy: 0.9975 - val_accuracy: 0.9378 - val_loss: 0.2124\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1163 - loss: 2.3009 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1142 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1135 - loss: 2.3018 - val_accuracy: 0.1060 - val_loss: 2.3021\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3011 - val_accuracy: 0.1060 - val_loss: 2.3020\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3008 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3006 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2987 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2982 - val_accuracy: 0.1060 - val_loss: 2.2990\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2979 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2977 - val_accuracy: 0.1060 - val_loss: 2.2986\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1139 - loss: 2.3010 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3004 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2996 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2991 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2986 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2983 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2981 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2977 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2975 - val_accuracy: 0.1060 - val_loss: 2.2983\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2972 - val_accuracy: 0.1060 - val_loss: 2.2978\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2969 - val_accuracy: 0.1060 - val_loss: 2.2978\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2967 - val_accuracy: 0.1060 - val_loss: 2.2975\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2964 - val_accuracy: 0.1060 - val_loss: 2.2972\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2961 - val_accuracy: 0.1060 - val_loss: 2.2969\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2958 - val_accuracy: 0.1060 - val_loss: 2.2964\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2955 - val_accuracy: 0.1060 - val_loss: 2.2961\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5088 - accuracy: 0.1139 - loss: 2.3015 - val_TopKCategoricalAccuracy: 0.5107 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5230 - accuracy: 0.1140 - loss: 2.3008 - val_TopKCategoricalAccuracy: 0.4996 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5150 - accuracy: 0.1140 - loss: 2.3006 - val_TopKCategoricalAccuracy: 0.5251 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5313 - accuracy: 0.1140 - loss: 2.3003 - val_TopKCategoricalAccuracy: 0.5363 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5340 - accuracy: 0.1140 - loss: 2.3001 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5095 - accuracy: 0.1100 - loss: 2.3017 - val_TopKCategoricalAccuracy: 0.5120 - val_accuracy: 0.1060 - val_loss: 2.3021\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5147 - accuracy: 0.1140 - loss: 2.3011 - val_TopKCategoricalAccuracy: 0.5103 - val_accuracy: 0.1060 - val_loss: 2.3021\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5184 - accuracy: 0.1140 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5208 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5200 - accuracy: 0.1140 - loss: 2.3005 - val_TopKCategoricalAccuracy: 0.5059 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5295 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5003 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5264 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5479 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5316 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5121 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5341 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5663 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5372 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5163 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5232 - accuracy: 0.1130 - loss: 2.3013 - val_TopKCategoricalAccuracy: 0.5301 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5270 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5137 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5289 - accuracy: 0.1140 - loss: 2.3004 - val_TopKCategoricalAccuracy: 0.5328 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5390 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5148 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5299 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5483 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5478 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5422 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5513 - accuracy: 0.1140 - loss: 2.2994 - val_TopKCategoricalAccuracy: 0.5459 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5405 - accuracy: 0.1140 - loss: 2.2992 - val_TopKCategoricalAccuracy: 0.5242 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5421 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5439 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5527 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.5341 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5340 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5309 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5674 - accuracy: 0.1140 - loss: 2.2982 - val_TopKCategoricalAccuracy: 0.5198 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5742 - accuracy: 0.1140 - loss: 2.2980 - val_TopKCategoricalAccuracy: 0.6049 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5519 - accuracy: 0.1140 - loss: 2.2977 - val_TopKCategoricalAccuracy: 0.5958 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5766 - accuracy: 0.1140 - loss: 2.2974 - val_TopKCategoricalAccuracy: 0.5969 - val_accuracy: 0.1060 - val_loss: 2.2983\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.0, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5162 - accuracy: 0.1144 - loss: 2.3014 - val_TopKCategoricalAccuracy: 0.5109 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5189 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5504 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5207 - accuracy: 0.1140 - loss: 2.3005 - val_TopKCategoricalAccuracy: 0.5487 - val_accuracy: 0.1060 - val_loss: 2.3014\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5235 - accuracy: 0.1140 - loss: 2.3003 - val_TopKCategoricalAccuracy: 0.5179 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5270 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5206 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5262 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5433 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5422 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5213 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5301 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5620 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5397 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5113 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5320 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5302 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5418 - accuracy: 0.1140 - loss: 2.2986 - val_TopKCategoricalAccuracy: 0.5178 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5590 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5500 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5466 - accuracy: 0.1140 - loss: 2.2981 - val_TopKCategoricalAccuracy: 0.5159 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5452 - accuracy: 0.1140 - loss: 2.2979 - val_TopKCategoricalAccuracy: 0.5913 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5390 - accuracy: 0.1140 - loss: 2.2976 - val_TopKCategoricalAccuracy: 0.5906 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5779 - accuracy: 0.1140 - loss: 2.2974 - val_TopKCategoricalAccuracy: 0.5802 - val_accuracy: 0.1060 - val_loss: 2.2983\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5760 - accuracy: 0.1140 - loss: 2.2972 - val_TopKCategoricalAccuracy: 0.5922 - val_accuracy: 0.1060 - val_loss: 2.2980\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5721 - accuracy: 0.1140 - loss: 2.2969 - val_TopKCategoricalAccuracy: 0.6237 - val_accuracy: 0.1060 - val_loss: 2.2977\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5662 - accuracy: 0.1140 - loss: 2.2966 - val_TopKCategoricalAccuracy: 0.5534 - val_accuracy: 0.1060 - val_loss: 2.2975\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5784 - accuracy: 0.1140 - loss: 2.2964 - val_TopKCategoricalAccuracy: 0.5299 - val_accuracy: 0.1060 - val_loss: 2.2973\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.6913 - loss: 1.0269 - val_accuracy: 0.8792 - val_loss: 0.4248\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8774 - loss: 0.4197 - val_accuracy: 0.8990 - val_loss: 0.3492\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8925 - loss: 0.3713 - val_accuracy: 0.9093 - val_loss: 0.3168\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9013 - loss: 0.3452 - val_accuracy: 0.9162 - val_loss: 0.2922\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.3310 - val_accuracy: 0.9172 - val_loss: 0.2912\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 1.0260 - val_accuracy: 0.8792 - val_loss: 0.4350\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.4346 - val_accuracy: 0.9007 - val_loss: 0.3475\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.3811 - val_accuracy: 0.9093 - val_loss: 0.3117\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8982 - loss: 0.3507 - val_accuracy: 0.9145 - val_loss: 0.2930\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.3346 - val_accuracy: 0.9197 - val_loss: 0.2841\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.3218 - val_accuracy: 0.9212 - val_loss: 0.2766\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9089 - loss: 0.3151 - val_accuracy: 0.9227 - val_loss: 0.2690\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.3070 - val_accuracy: 0.9235 - val_loss: 0.2676\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.3049 - val_accuracy: 0.9243 - val_loss: 0.2647\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.3007 - val_accuracy: 0.9223 - val_loss: 0.2689\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6816 - loss: 1.0392 - val_accuracy: 0.8783 - val_loss: 0.4355\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.4260 - val_accuracy: 0.9010 - val_loss: 0.3368\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.3701 - val_accuracy: 0.9132 - val_loss: 0.3076\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9014 - loss: 0.3424 - val_accuracy: 0.9167 - val_loss: 0.2867\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9048 - loss: 0.3287 - val_accuracy: 0.9178 - val_loss: 0.2819\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9093 - loss: 0.3181 - val_accuracy: 0.9230 - val_loss: 0.2692\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9099 - loss: 0.3132 - val_accuracy: 0.9227 - val_loss: 0.2735\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9128 - loss: 0.3029 - val_accuracy: 0.9252 - val_loss: 0.2654\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9142 - loss: 0.3017 - val_accuracy: 0.9237 - val_loss: 0.2727\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9149 - loss: 0.2973 - val_accuracy: 0.9235 - val_loss: 0.2653\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9147 - loss: 0.2963 - val_accuracy: 0.9263 - val_loss: 0.2603\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9166 - loss: 0.2928 - val_accuracy: 0.9244 - val_loss: 0.2638\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9170 - loss: 0.2909 - val_accuracy: 0.9268 - val_loss: 0.2587\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2890 - val_accuracy: 0.9262 - val_loss: 0.2676\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9178 - loss: 0.2873 - val_accuracy: 0.9278 - val_loss: 0.2600\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.6769 - loss: 1.0510 - val_accuracy: 0.8742 - val_loss: 0.4413\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8738 - loss: 0.4275 - val_accuracy: 0.9046 - val_loss: 0.3388\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8936 - loss: 0.3668 - val_accuracy: 0.9103 - val_loss: 0.3048\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.3457 - val_accuracy: 0.9154 - val_loss: 0.2950\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.3283 - val_accuracy: 0.9183 - val_loss: 0.2799\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9078 - loss: 0.3202 - val_accuracy: 0.9221 - val_loss: 0.2713\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.3097 - val_accuracy: 0.9198 - val_loss: 0.2805\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.3069 - val_accuracy: 0.9233 - val_loss: 0.2666\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9134 - loss: 0.2999 - val_accuracy: 0.9249 - val_loss: 0.2660\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9137 - loss: 0.3001 - val_accuracy: 0.9254 - val_loss: 0.2636\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9153 - loss: 0.2965 - val_accuracy: 0.9267 - val_loss: 0.2602\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9154 - loss: 0.2941 - val_accuracy: 0.9259 - val_loss: 0.2631\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9162 - loss: 0.2936 - val_accuracy: 0.9252 - val_loss: 0.2643\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9184 - loss: 0.2887 - val_accuracy: 0.9267 - val_loss: 0.2597\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9187 - loss: 0.2884 - val_accuracy: 0.9294 - val_loss: 0.2554\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9186 - loss: 0.2871 - val_accuracy: 0.9277 - val_loss: 0.2564\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9181 - loss: 0.2836 - val_accuracy: 0.9291 - val_loss: 0.2596\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9191 - loss: 0.2827 - val_accuracy: 0.9281 - val_loss: 0.2559\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step - accuracy: 0.9202 - loss: 0.2813 - val_accuracy: 0.9287 - val_loss: 0.2586\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9205 - loss: 0.2819 - val_accuracy: 0.9273 - val_loss: 0.2645\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - TopKCategoricalAccuracy: 0.9448 - accuracy: 0.6986 - loss: 1.0165 - val_TopKCategoricalAccuracy: 0.9918 - val_accuracy: 0.8778 - val_loss: 0.4255\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - TopKCategoricalAccuracy: 0.9926 - accuracy: 0.8729 - loss: 0.4246 - val_TopKCategoricalAccuracy: 0.9933 - val_accuracy: 0.8965 - val_loss: 0.3563\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - TopKCategoricalAccuracy: 0.9940 - accuracy: 0.8904 - loss: 0.3730 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9078 - val_loss: 0.3178\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9944 - accuracy: 0.8997 - loss: 0.3479 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9145 - val_loss: 0.2942\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9949 - accuracy: 0.9053 - loss: 0.3312 - val_TopKCategoricalAccuracy: 0.9946 - val_accuracy: 0.9174 - val_loss: 0.2853\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9449 - accuracy: 0.6955 - loss: 1.0327 - val_TopKCategoricalAccuracy: 0.9914 - val_accuracy: 0.8816 - val_loss: 0.4257\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9927 - accuracy: 0.8773 - loss: 0.4217 - val_TopKCategoricalAccuracy: 0.9939 - val_accuracy: 0.9054 - val_loss: 0.3329\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9941 - accuracy: 0.8938 - loss: 0.3657 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9104 - val_loss: 0.3030\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9943 - accuracy: 0.9022 - loss: 0.3408 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9174 - val_loss: 0.2865\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9946 - accuracy: 0.9055 - loss: 0.3246 - val_TopKCategoricalAccuracy: 0.9943 - val_accuracy: 0.9201 - val_loss: 0.2782\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9949 - accuracy: 0.9089 - loss: 0.3171 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9240 - val_loss: 0.2705\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9121 - loss: 0.3094 - val_TopKCategoricalAccuracy: 0.9950 - val_accuracy: 0.9227 - val_loss: 0.2687\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9118 - loss: 0.3036 - val_TopKCategoricalAccuracy: 0.9949 - val_accuracy: 0.9252 - val_loss: 0.2650\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9151 - loss: 0.3003 - val_TopKCategoricalAccuracy: 0.9953 - val_accuracy: 0.9243 - val_loss: 0.2649\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9949 - accuracy: 0.9154 - loss: 0.2955 - val_TopKCategoricalAccuracy: 0.9953 - val_accuracy: 0.9254 - val_loss: 0.2639\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9474 - accuracy: 0.6784 - loss: 1.0425 - val_TopKCategoricalAccuracy: 0.9912 - val_accuracy: 0.8689 - val_loss: 0.4497\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9921 - accuracy: 0.8697 - loss: 0.4413 - val_TopKCategoricalAccuracy: 0.9940 - val_accuracy: 0.8998 - val_loss: 0.3429\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9941 - accuracy: 0.8913 - loss: 0.3739 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9083 - val_loss: 0.3112\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9947 - accuracy: 0.9005 - loss: 0.3453 - val_TopKCategoricalAccuracy: 0.9942 - val_accuracy: 0.9155 - val_loss: 0.2943\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9943 - accuracy: 0.9048 - loss: 0.3309 - val_TopKCategoricalAccuracy: 0.9946 - val_accuracy: 0.9212 - val_loss: 0.2829\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9075 - loss: 0.3197 - val_TopKCategoricalAccuracy: 0.9944 - val_accuracy: 0.9212 - val_loss: 0.2734\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9094 - loss: 0.3142 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9227 - val_loss: 0.2678\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9950 - accuracy: 0.9133 - loss: 0.3066 - val_TopKCategoricalAccuracy: 0.9948 - val_accuracy: 0.9256 - val_loss: 0.2649\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9949 - accuracy: 0.9139 - loss: 0.3033 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9233 - val_loss: 0.2665\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9953 - accuracy: 0.9143 - loss: 0.2998 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9204 - val_loss: 0.2714\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9142 - loss: 0.2980 - val_TopKCategoricalAccuracy: 0.9952 - val_accuracy: 0.9212 - val_loss: 0.2696\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9951 - accuracy: 0.9163 - loss: 0.2937 - val_TopKCategoricalAccuracy: 0.9952 - val_accuracy: 0.9237 - val_loss: 0.2668\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9954 - accuracy: 0.9176 - loss: 0.2923 - val_TopKCategoricalAccuracy: 0.9956 - val_accuracy: 0.9272 - val_loss: 0.2606\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9183 - loss: 0.2879 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9208 - val_loss: 0.2722\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9953 - accuracy: 0.9178 - loss: 0.2864 - val_TopKCategoricalAccuracy: 0.9955 - val_accuracy: 0.9271 - val_loss: 0.2574\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=adam, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9408 - accuracy: 0.6914 - loss: 1.0309 - val_TopKCategoricalAccuracy: 0.9922 - val_accuracy: 0.8735 - val_loss: 0.4435\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9926 - accuracy: 0.8704 - loss: 0.4394 - val_TopKCategoricalAccuracy: 0.9937 - val_accuracy: 0.8978 - val_loss: 0.3575\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9937 - accuracy: 0.8881 - loss: 0.3797 - val_TopKCategoricalAccuracy: 0.9945 - val_accuracy: 0.9078 - val_loss: 0.3160\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9943 - accuracy: 0.8985 - loss: 0.3514 - val_TopKCategoricalAccuracy: 0.9940 - val_accuracy: 0.9152 - val_loss: 0.2970\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9946 - accuracy: 0.9049 - loss: 0.3348 - val_TopKCategoricalAccuracy: 0.9949 - val_accuracy: 0.9181 - val_loss: 0.2831\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9075 - loss: 0.3217 - val_TopKCategoricalAccuracy: 0.9952 - val_accuracy: 0.9182 - val_loss: 0.2825\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9954 - accuracy: 0.9101 - loss: 0.3138 - val_TopKCategoricalAccuracy: 0.9950 - val_accuracy: 0.9234 - val_loss: 0.2681\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9126 - loss: 0.3075 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9232 - val_loss: 0.2686\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.9954 - accuracy: 0.9131 - loss: 0.3013 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9256 - val_loss: 0.2639\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9151 - loss: 0.2991 - val_TopKCategoricalAccuracy: 0.9957 - val_accuracy: 0.9245 - val_loss: 0.2633\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9144 - loss: 0.2974 - val_TopKCategoricalAccuracy: 0.9956 - val_accuracy: 0.9237 - val_loss: 0.2652\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9954 - accuracy: 0.9167 - loss: 0.2936 - val_TopKCategoricalAccuracy: 0.9952 - val_accuracy: 0.9267 - val_loss: 0.2635\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9952 - accuracy: 0.9174 - loss: 0.2899 - val_TopKCategoricalAccuracy: 0.9955 - val_accuracy: 0.9225 - val_loss: 0.2682\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9958 - accuracy: 0.9168 - loss: 0.2893 - val_TopKCategoricalAccuracy: 0.9954 - val_accuracy: 0.9268 - val_loss: 0.2610\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9174 - loss: 0.2882 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9258 - val_loss: 0.2602\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9190 - loss: 0.2845 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9252 - val_loss: 0.2618\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9955 - accuracy: 0.9189 - loss: 0.2834 - val_TopKCategoricalAccuracy: 0.9958 - val_accuracy: 0.9268 - val_loss: 0.2585\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9198 - loss: 0.2822 - val_TopKCategoricalAccuracy: 0.9959 - val_accuracy: 0.9282 - val_loss: 0.2557\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9956 - accuracy: 0.9183 - loss: 0.2824 - val_TopKCategoricalAccuracy: 0.9955 - val_accuracy: 0.9277 - val_loss: 0.2575\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.9957 - accuracy: 0.9201 - loss: 0.2814 - val_TopKCategoricalAccuracy: 0.9953 - val_accuracy: 0.9275 - val_loss: 0.2599\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1160 - loss: 2.3014 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3008 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3006 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3003 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3002 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1111 - loss: 2.3018 - val_accuracy: 0.1060 - val_loss: 2.3022\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3012 - val_accuracy: 0.1060 - val_loss: 2.3020\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3010 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3007 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3006 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3002 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2998 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.1135 - loss: 2.3016 - val_accuracy: 0.1060 - val_loss: 2.3019\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.1140 - loss: 2.3009 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3004 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3001 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.3000 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2995 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2992 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2990 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2987 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2985 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2983 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2980 - val_accuracy: 0.1060 - val_loss: 2.2988\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2978 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1164 - loss: 2.3005 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2999 - val_accuracy: 0.1060 - val_loss: 2.3009\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2997 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2994 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2993 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2989 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2988 - val_accuracy: 0.1060 - val_loss: 2.2995\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2984 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2983 - val_accuracy: 0.1060 - val_loss: 2.2991\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2979 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2976 - val_accuracy: 0.1060 - val_loss: 2.2984\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2973 - val_accuracy: 0.1060 - val_loss: 2.2981\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2970 - val_accuracy: 0.1060 - val_loss: 2.2977\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2968 - val_accuracy: 0.1060 - val_loss: 2.2974\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2965 - val_accuracy: 0.1060 - val_loss: 2.2974\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2962 - val_accuracy: 0.1060 - val_loss: 2.2970\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.1140 - loss: 2.2960 - val_accuracy: 0.1060 - val_loss: 2.2966\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2956 - val_accuracy: 0.1060 - val_loss: 2.2966\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2953 - val_accuracy: 0.1060 - val_loss: 2.2960\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.1140 - loss: 2.2950 - val_accuracy: 0.1060 - val_loss: 2.2958\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5149 - accuracy: 0.1134 - loss: 2.3015 - val_TopKCategoricalAccuracy: 0.5303 - val_accuracy: 0.1060 - val_loss: 2.3019\n",
      "Epoch 2/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5216 - accuracy: 0.1140 - loss: 2.3009 - val_TopKCategoricalAccuracy: 0.5127 - val_accuracy: 0.1060 - val_loss: 2.3018\n",
      "Epoch 3/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5248 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5196 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 4/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5248 - accuracy: 0.1140 - loss: 2.3005 - val_TopKCategoricalAccuracy: 0.5132 - val_accuracy: 0.1060 - val_loss: 2.3013\n",
      "Epoch 5/5\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5273 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5418 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5326 - accuracy: 0.1130 - loss: 2.3008 - val_TopKCategoricalAccuracy: 0.5178 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 2/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5329 - accuracy: 0.1140 - loss: 2.3003 - val_TopKCategoricalAccuracy: 0.5134 - val_accuracy: 0.1060 - val_loss: 2.3011\n",
      "Epoch 3/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5336 - accuracy: 0.1140 - loss: 2.3000 - val_TopKCategoricalAccuracy: 0.5258 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 4/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5339 - accuracy: 0.1140 - loss: 2.2997 - val_TopKCategoricalAccuracy: 0.5148 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 5/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5334 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5289 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 6/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5399 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5948 - val_accuracy: 0.1060 - val_loss: 2.3000\n",
      "Epoch 7/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5511 - accuracy: 0.1140 - loss: 2.2991 - val_TopKCategoricalAccuracy: 0.5144 - val_accuracy: 0.1060 - val_loss: 2.2999\n",
      "Epoch 8/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5452 - accuracy: 0.1140 - loss: 2.2989 - val_TopKCategoricalAccuracy: 0.5293 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 9/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5455 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.5901 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 10/10\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5564 - accuracy: 0.1140 - loss: 2.2984 - val_TopKCategoricalAccuracy: 0.5667 - val_accuracy: 0.1060 - val_loss: 2.2992\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5180 - accuracy: 0.1157 - loss: 2.3014 - val_TopKCategoricalAccuracy: 0.5458 - val_accuracy: 0.1060 - val_loss: 2.3016\n",
      "Epoch 2/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5206 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5462 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 3/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5267 - accuracy: 0.1140 - loss: 2.3005 - val_TopKCategoricalAccuracy: 0.5123 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 4/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5273 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 5/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5284 - accuracy: 0.1140 - loss: 2.3001 - val_TopKCategoricalAccuracy: 0.5561 - val_accuracy: 0.1060 - val_loss: 2.3007\n",
      "Epoch 6/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5348 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.3005\n",
      "Epoch 7/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5412 - accuracy: 0.1140 - loss: 2.2995 - val_TopKCategoricalAccuracy: 0.5486 - val_accuracy: 0.1060 - val_loss: 2.3004\n",
      "Epoch 8/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5426 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5154 - val_accuracy: 0.1060 - val_loss: 2.3001\n",
      "Epoch 9/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5406 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.5234 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 10/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5476 - accuracy: 0.1140 - loss: 2.2988 - val_TopKCategoricalAccuracy: 0.5776 - val_accuracy: 0.1060 - val_loss: 2.2996\n",
      "Epoch 11/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5423 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.5156 - val_accuracy: 0.1060 - val_loss: 2.2994\n",
      "Epoch 12/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5591 - accuracy: 0.1140 - loss: 2.2983 - val_TopKCategoricalAccuracy: 0.6507 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 13/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5595 - accuracy: 0.1140 - loss: 2.2981 - val_TopKCategoricalAccuracy: 0.5840 - val_accuracy: 0.1060 - val_loss: 2.2987\n",
      "Epoch 14/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5564 - accuracy: 0.1140 - loss: 2.2979 - val_TopKCategoricalAccuracy: 0.6326 - val_accuracy: 0.1060 - val_loss: 2.2985\n",
      "Epoch 15/15\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5688 - accuracy: 0.1140 - loss: 2.2975 - val_TopKCategoricalAccuracy: 0.6127 - val_accuracy: 0.1060 - val_loss: 2.2984\n",
      "Testing: hidden_units=[256, 128], activation=tanh, dropout=0.3, optimizer=sgd, loss=categorical_crossentropy\n",
      "Epoch 1/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - TopKCategoricalAccuracy: 0.5138 - accuracy: 0.1134 - loss: 2.3015 - val_TopKCategoricalAccuracy: 0.5104 - val_accuracy: 0.1060 - val_loss: 2.3020\n",
      "Epoch 2/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5173 - accuracy: 0.1140 - loss: 2.3010 - val_TopKCategoricalAccuracy: 0.5373 - val_accuracy: 0.1060 - val_loss: 2.3017\n",
      "Epoch 3/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5220 - accuracy: 0.1140 - loss: 2.3007 - val_TopKCategoricalAccuracy: 0.5155 - val_accuracy: 0.1060 - val_loss: 2.3015\n",
      "Epoch 4/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5228 - accuracy: 0.1140 - loss: 2.3005 - val_TopKCategoricalAccuracy: 0.5282 - val_accuracy: 0.1060 - val_loss: 2.3012\n",
      "Epoch 5/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5238 - accuracy: 0.1140 - loss: 2.3002 - val_TopKCategoricalAccuracy: 0.5804 - val_accuracy: 0.1060 - val_loss: 2.3010\n",
      "Epoch 6/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5303 - accuracy: 0.1140 - loss: 2.2999 - val_TopKCategoricalAccuracy: 0.5132 - val_accuracy: 0.1060 - val_loss: 2.3008\n",
      "Epoch 7/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5311 - accuracy: 0.1140 - loss: 2.2998 - val_TopKCategoricalAccuracy: 0.5147 - val_accuracy: 0.1060 - val_loss: 2.3006\n",
      "Epoch 8/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5343 - accuracy: 0.1140 - loss: 2.2996 - val_TopKCategoricalAccuracy: 0.5375 - val_accuracy: 0.1060 - val_loss: 2.3003\n",
      "Epoch 9/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5368 - accuracy: 0.1140 - loss: 2.2993 - val_TopKCategoricalAccuracy: 0.5251 - val_accuracy: 0.1060 - val_loss: 2.3002\n",
      "Epoch 10/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5443 - accuracy: 0.1140 - loss: 2.2990 - val_TopKCategoricalAccuracy: 0.6152 - val_accuracy: 0.1060 - val_loss: 2.2998\n",
      "Epoch 11/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5454 - accuracy: 0.1140 - loss: 2.2987 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2997\n",
      "Epoch 12/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5395 - accuracy: 0.1140 - loss: 2.2985 - val_TopKCategoricalAccuracy: 0.6003 - val_accuracy: 0.1060 - val_loss: 2.2993\n",
      "Epoch 13/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5539 - accuracy: 0.1140 - loss: 2.2982 - val_TopKCategoricalAccuracy: 0.5979 - val_accuracy: 0.1060 - val_loss: 2.2990\n",
      "Epoch 14/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5518 - accuracy: 0.1140 - loss: 2.2980 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2989\n",
      "Epoch 15/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5534 - accuracy: 0.1140 - loss: 2.2978 - val_TopKCategoricalAccuracy: 0.5128 - val_accuracy: 0.1060 - val_loss: 2.2986\n",
      "Epoch 16/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5562 - accuracy: 0.1140 - loss: 2.2975 - val_TopKCategoricalAccuracy: 0.5341 - val_accuracy: 0.1060 - val_loss: 2.2982\n",
      "Epoch 17/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5578 - accuracy: 0.1140 - loss: 2.2972 - val_TopKCategoricalAccuracy: 0.5167 - val_accuracy: 0.1060 - val_loss: 2.2978\n",
      "Epoch 18/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5681 - accuracy: 0.1140 - loss: 2.2970 - val_TopKCategoricalAccuracy: 0.5865 - val_accuracy: 0.1060 - val_loss: 2.2977\n",
      "Epoch 19/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - TopKCategoricalAccuracy: 0.5617 - accuracy: 0.1140 - loss: 2.2966 - val_TopKCategoricalAccuracy: 0.5923 - val_accuracy: 0.1060 - val_loss: 2.2974\n",
      "Epoch 20/20\n",
      "\u001b[1m375/375\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - TopKCategoricalAccuracy: 0.5586 - accuracy: 0.1140 - loss: 2.2964 - val_TopKCategoricalAccuracy: 0.5458 - val_accuracy: 0.1060 - val_loss: 2.2970\n",
      "    hidden_units activation  dropout_rate optimizer                      loss  \\\n",
      "67    [256, 128]       relu           0.0      adam  categorical_crossentropy   \n",
      "71    [256, 128]       relu           0.0      adam  categorical_crossentropy   \n",
      "83    [256, 128]       relu           0.3      adam  categorical_crossentropy   \n",
      "87    [256, 128]       relu           0.3      adam  categorical_crossentropy   \n",
      "70    [256, 128]       relu           0.0      adam  categorical_crossentropy   \n",
      "66    [256, 128]       relu           0.0      adam  categorical_crossentropy   \n",
      "86    [256, 128]       relu           0.3      adam  categorical_crossentropy   \n",
      "82    [256, 128]       relu           0.3      adam  categorical_crossentropy   \n",
      "99    [256, 128]       tanh           0.0      adam  categorical_crossentropy   \n",
      "103   [256, 128]       tanh           0.0      adam  categorical_crossentropy   \n",
      "\n",
      "                                 metrics  val_accuracy  \\\n",
      "67                            [accuracy]      0.967167   \n",
      "71   [accuracy, TopKCategoricalAccuracy]      0.963792   \n",
      "83                            [accuracy]      0.962271   \n",
      "87   [accuracy, TopKCategoricalAccuracy]      0.960646   \n",
      "70   [accuracy, TopKCategoricalAccuracy]      0.954896   \n",
      "66                            [accuracy]      0.953292   \n",
      "86   [accuracy, TopKCategoricalAccuracy]      0.950500   \n",
      "82                            [accuracy]      0.948292   \n",
      "99                            [accuracy]      0.940271   \n",
      "103  [accuracy, TopKCategoricalAccuracy]      0.939958   \n",
      "\n",
      "                                            model  \\\n",
      "67    <Sequential name=sequential_74, built=True>   \n",
      "71    <Sequential name=sequential_78, built=True>   \n",
      "83    <Sequential name=sequential_90, built=True>   \n",
      "87    <Sequential name=sequential_94, built=True>   \n",
      "70    <Sequential name=sequential_77, built=True>   \n",
      "66    <Sequential name=sequential_73, built=True>   \n",
      "86    <Sequential name=sequential_93, built=True>   \n",
      "82    <Sequential name=sequential_89, built=True>   \n",
      "99   <Sequential name=sequential_106, built=True>   \n",
      "103  <Sequential name=sequential_110, built=True>   \n",
      "\n",
      "                                               history  \n",
      "67   <keras.src.callbacks.history.History object at...  \n",
      "71   <keras.src.callbacks.history.History object at...  \n",
      "83   <keras.src.callbacks.history.History object at...  \n",
      "87   <keras.src.callbacks.history.History object at...  \n",
      "70   <keras.src.callbacks.history.History object at...  \n",
      "66   <keras.src.callbacks.history.History object at...  \n",
      "86   <keras.src.callbacks.history.History object at...  \n",
      "82   <keras.src.callbacks.history.History object at...  \n",
      "99   <keras.src.callbacks.history.History object at...  \n",
      "103  <keras.src.callbacks.history.History object at...  \n"
     ]
    }
   ],
   "source": [
    "def hyperparameter_search(x_train, y_train, x_val, y_val,\n",
    "                                   hidden_units_list=[[128], [256, 128]],\n",
    "                                   activations=['relu', 'tanh'],\n",
    "                                   dropout_rates=[0.0, 0.3, 0.5],\n",
    "                                   optimizers=['adam', 'sgd'],\n",
    "                                   losses=['categorical_crossentropy'],\n",
    "                                   metrics_list=[['accuracy', 'precision', 'recall', 'TopKCategoricalAccuracy']],\n",
    "                                   epochs=[5, 10, 15, 20],\n",
    "                                   batch_size=128):\n",
    "    \"\"\"\n",
    "    Test all combinations of hyperparameters and return results DataFrame.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for hidden_units, activation, dropout_rate, optimizer, loss, metrics, epochs_n in itertools.product(\n",
    "        hidden_units_list, activations, dropout_rates, optimizers, losses, metrics_list, epochs\n",
    "    ):\n",
    "        print(f\"Testing: hidden_units={hidden_units}, activation={activation}, dropout={dropout_rate}, optimizer={optimizer}, loss={loss}\")\n",
    "        model = create_mlp(hidden_units=hidden_units, activation=activation, dropout_rate=dropout_rate)\n",
    "        model, history = train_model(model, x_train, y_train, x_val, y_val,\n",
    "                                     optimizer=optimizer, loss=loss, metrics=metrics,\n",
    "                                     epochs=epochs_n, batch_size=batch_size)\n",
    "\n",
    "        val_acc = max(history.history[metrics[0]])\n",
    "        results.append({\n",
    "            'hidden_units': hidden_units,\n",
    "            'activation': activation,\n",
    "            'dropout_rate': dropout_rate,\n",
    "            'optimizer': optimizer,\n",
    "            'loss': loss,\n",
    "            'metrics': metrics,\n",
    "            'val_accuracy': val_acc,\n",
    "            'model': model,\n",
    "            'history': history\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "results = hyperparameter_search(\n",
    "    x_train, y_train,\n",
    "    x_val, y_val,\n",
    "    hidden_units_list=[[128], [256,128]],\n",
    "    activations=['relu', 'tanh'],\n",
    "    dropout_rates=[0.0, 0.3],\n",
    "    optimizers=['adam', 'sgd'],\n",
    "    losses=['categorical_crossentropy'],\n",
    "    metrics_list=[['accuracy'], ['accuracy','TopKCategoricalAccuracy']],\n",
    "    epochs=[5, 10, 15, 20]\n",
    ")\n",
    "\n",
    "results_sorted = results.sort_values(by='val_accuracy', ascending=False)\n",
    "print(results_sorted.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab08cedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(history):\n",
    "    \"\"\"\n",
    "    Plot train and validation accuracy/loss curves from history.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "    plt.title('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b060bad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_row = results_sorted.iloc[0]\n",
    "best_model = best_row['model']\n",
    "best_history = best_row['history']\n",
    "\n",
    "plot_learning_curves(best_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a2cfda89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, x_test, y_test, top_n_wrong=10):\n",
    "    \"\"\"\n",
    "    Evaluate model on test set and show misclassified examples.\n",
    "    \"\"\"\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "    y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "    y_true = np.argmax(y_test, axis=1)\n",
    "    wrong = np.where(y_pred != y_true)[0]\n",
    "    print(f\"Number of misclassified examples: {len(wrong)}\")\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    for i, idx in enumerate(wrong[:top_n_wrong]):\n",
    "        plt.subplot(2, top_n_wrong//2, i+1)\n",
    "        plt.imshow(x_test[idx].reshape(28,28), cmap='gray')\n",
    "        plt.title(f\"True:{y_true[idx]}, Pred:{y_pred[idx]}\")\n",
    "        plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f094e5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9269 - loss: 20.8291\n",
      "Test accuracy: 0.9269\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step\n",
      "Number of misclassified examples: 731\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_model(best_model, x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
